{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Ive2uESMyq"
      },
      "source": [
        "# Edited: Sama\n",
        "# Spleen 3D Regression with MONAI\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXVAKJOVSMyw"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHBrChiqSMyw",
        "outputId": "f610c8a0-1f09-47e0-f5bb-8b3a2c68e0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-14 08:42:45.086536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-14 08:42:45.086588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-14 08:42:45.086636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-14 08:42:47.235992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "\n",
        "\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import (EnsureChannelFirstd, Compose, CropForegroundd, LoadImaged, Orientationd, RandCropByPosNegLabeld, ScaleIntensityRanged, Spacingd)\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6t0wW8uSMy4"
      },
      "source": [
        "## Set MSD Spleen dataset path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsYq65ABSMy5",
        "outputId": "2e2716d1-b1b9-4634-e086-713228d217c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir = '/content/drive/My Drive/MONAI_data'\n",
        "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
        "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
        "os.makedirs(root_dir, exist_ok=True)\n",
        "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
        "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)\n",
        "\n",
        "train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "# Create data dictionaries\n",
        "data_dicts = [{\"image\": img, \"target\": img} for img in train_images]\n",
        "# making  smaller input to save time for practing stage:\n",
        "train_files, val_files = data_dicts[-9:], data_dicts[-9:]\n",
        "\n",
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDxnsIeUSMy7"
      },
      "source": [
        "## Define CacheDataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zrTrbKJSMy7",
        "outputId": "ce87a58c-2805-44a3-c4fb-454ab7b2f456",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
            "  warn_deprecated(argname, msg, warning_category)\n",
            "Loading dataset: 100%|██████████| 9/9 [00:46<00:00,  5.20s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loading dataset: 100%|██████████| 9/9 [00:30<00:00,  3.36s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"target\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"target\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"],a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"target\"], source_key=\"image\"),\n",
        "        Orientationd(keys=[\"image\", \"target\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"target\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"image\", \"target\"],\n",
        "            label_key=\"target\", spatial_size=(96, 96, 96), pos=1, neg=1, num_samples=4,\n",
        "            image_key=\"image\",\n",
        "            image_threshold=0,\n",
        "        ),])\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"target\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"target\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\", \"target\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"target\"], source_key=\"image\"),\n",
        "        Orientationd(keys=[\"image\", \"target\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"target\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),])\n",
        "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
        "\n",
        "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2Xoxn-SMy7"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5mkh6PBSMy8"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    act=(nn.ReLU, {\"inplace\": True}),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        ").to(device)\n",
        "\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV-viYVSSMy8"
      },
      "source": [
        "## Execute a typical PyTorch training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s_VdN05mSMy8",
        "outputId": "bcce9d2b-01b0-4396-80a7-9848dcd98ca1",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRITICAL:dev_collate:> collate dict key \"image\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"image\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"image\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"image\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 271, 244, 241] at entry 0 and [1, 228, 158, 113] at entry 1, shape [torch.Size([1, 271, 244, 241]), torch.Size([1, 228, 158, 113])] in collate([metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])])\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 233, 209, 101] at entry 0 and [1, 305, 267, 124] at entry 1, shape [torch.Size([1, 233, 209, 101]), torch.Size([1, 305, 267, 124])] in collate([metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])])\n",
            "CRITICAL:dev_collate:> collate dict key \"target\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"target\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 289, 263, 108] at entry 0 and [1, 257, 205, 148] at entry 1, shape [torch.Size([1, 289, 263, 108]), torch.Size([1, 257, 205, 148])] in collate([metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])])\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 268, 218, 114] at entry 0 and [1, 231, 166, 198] at entry 1, shape [torch.Size([1, 268, 218, 114]), torch.Size([1, 231, 166, 198])] in collate([metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), metatensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])])\n",
            "CRITICAL:dev_collate:> collate dict key \"target\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"target\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 233, 209, 101] at entry 0 and [1, 305, 267, 124] at entry 1, shape [torch.Size([1, 233, 209, 101]), torch.Size([1, 305, 267, 124])] in collate([metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]]), metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]])])\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 271, 244, 241] at entry 0 and [1, 228, 158, 113] at entry 1, shape [torch.Size([1, 271, 244, 241]), torch.Size([1, 228, 158, 113])] in collate([metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1002., -1002., -1003.,  ...,  -999., -1002., -1002.],\n",
            "          [ -998.,  -998., -1007.,  ..., -1011., -1007., -1007.],\n",
            "          [ -995.,  -995.,  -992.,  ...,  -997., -1011., -1011.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1003., -1003., -1004.,  ..., -1008., -1013., -1013.],\n",
            "          [-1001., -1001., -1005.,  ..., -1006., -1009., -1009.],\n",
            "          [ -997.,  -997., -1007.,  ..., -1000., -1004., -1004.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1000., -1000.,  -989.,  ..., -1002., -1008., -1008.],\n",
            "          [-1005., -1005., -1001.,  ..., -1001., -1007., -1007.],\n",
            "          [-1003., -1003., -1008.,  ..., -1002., -1004., -1004.]]]]), metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]])])\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_start_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_start_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 268, 218, 114] at entry 0 and [1, 231, 166, 198] at entry 1, shape [torch.Size([1, 268, 218, 114]), torch.Size([1, 231, 166, 198])] in collate([metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]]), metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]])])\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_end_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_start_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> E: stack expects each tensor to be equal size, but got [1, 289, 263, 108] at entry 0 and [1, 257, 205, 148] at entry 1, shape [torch.Size([1, 289, 263, 108]), torch.Size([1, 257, 205, 148])] in collate([metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]]), metatensor([[[[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]],\n",
            "\n",
            "         [[-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          ...,\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.],\n",
            "          [-1024., -1024., -1024.,  ..., -1024., -1024., -1024.]]]])])\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_end_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_start_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_end_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:> collate dict key \"foreground_end_coord\" out of 4 keys\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n",
            "CRITICAL:dev_collate:>> collate/stack a list of numpy arrays\n",
            "CRITICAL:dev_collate:>> collate/stack a list of tensors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-faf89304aeeb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         inputs, labels = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/monai/data/utils.py\", line 514, in list_data_collate\n    ret[key] = collate_fn(data_for_batch)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/monai/data/utils.py\", line 458, in collate_meta_tensor_fn\n    collated = collate_fn(batch)  # type: ignore\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n  File \"/usr/local/lib/python3.10/dist-packages/monai/data/meta_tensor.py\", line 282, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 1386, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: Trying to resize storage that is not resizable\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.10/dist-packages/monai/data/utils.py\", line 529, in list_data_collate\n    raise RuntimeError(re_str) from re\nRuntimeError: Trying to resize storage that is not resizable\n"
          ]
        }
      ],
      "source": [
        "\n",
        "max_epochs = 10\n",
        "val_interval = 2\n",
        "best_metric = float('inf')\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"target\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"target\"].to(device),\n",
        "                )\n",
        "                roi_size = (160, 160, 160)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
        "                # Compute MSE for current iteration\n",
        "                val_loss += loss_function(val_outputs, val_labels).item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            metric_values.append(val_loss)\n",
        "            if val_loss < best_metric:\n",
        "                best_metric = val_loss\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current val loss: {val_loss:.4f}\"\n",
        "                f\"\\nbest val loss: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iVEOOP5SMy8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWb3MrCSMy8"
      },
      "source": [
        "## Plot the loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY99alRpSMy9"
      },
      "outputs": [],
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUxTcCeWSMy9"
      },
      "source": [
        "## Check best model output with the input image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JAq2JwuSMy9"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(val_loader):\n",
        "        roi_size = (160, 160, 160)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, model)\n",
        "\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"target {i}\")\n",
        "        plt.imshow(val_data[\"target\"][0, 0, :, :, 80], cmap=\"gray\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        output_slice = val_outputs.detach().cpu()[0, 0, :, :, 80]\n",
        "        # Assuming the output values are normalized, adjust if not\n",
        "        plt.imshow(output_slice, cmap=\"gray\")\n",
        "        plt.show()\n",
        "        if i == 0:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kI2W3XqHAw3"
      },
      "source": [
        "---------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBXajIBAJgcQ"
      },
      "outputs": [],
      "source": [
        "# val_org_transforms = Compose(\n",
        "#     [\n",
        "#         LoadImaged(keys=[\"image\", \"target\"]),\n",
        "#         EnsureChannelFirstd(keys=[\"image\", \"target\"]),\n",
        "#         Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "#         Spacingd(keys=[\"image\"], pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
        "#         ScaleIntensityRanged(\n",
        "#             keys=[\"image\"],\n",
        "#             a_min=-57,\n",
        "#             a_max=164,\n",
        "#             b_min=0.0,\n",
        "#             b_max=1.0,\n",
        "#             clip=True,\n",
        "#         ),\n",
        "#         CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# val_org_ds = Dataset(data=val_files, transform=val_org_transforms)\n",
        "# val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "# post_transforms = Compose(\n",
        "#     [\n",
        "#         Invertd(\n",
        "#             keys=\"pred\",\n",
        "#             transform=val_org_transforms,\n",
        "#             orig_keys=\"image\",\n",
        "#             meta_keys=\"pred_meta_dict\",\n",
        "#             orig_meta_keys=\"image_meta_dict\",\n",
        "#             meta_key_postfix=\"meta_dict\",\n",
        "#             nearest_interp=False,\n",
        "#             to_tensor=True,\n",
        "#             device=\"cpu\",\n",
        "#         ),\n",
        "#         AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
        "#         AsDiscreted(keys=\"target\", to_onehot=2),\n",
        "#     ]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bEDXMFDHCFF"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "# model.eval()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for val_data in val_org_loader:\n",
        "#         val_inputs = val_data[\"image\"].to(device)\n",
        "#         roi_size = (160, 160, 160)\n",
        "#         sw_batch_size = 4\n",
        "#         val_data[\"pred\"] = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
        "#         val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
        "#         val_outputs, val_labels = from_engine([\"pred\", \"target\"])(val_data)\n",
        "#         # compute metric for current iteration\n",
        "#         dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "#     # aggregate the final mean dice result\n",
        "#     metric_org = dice_metric.aggregate().item()\n",
        "#     # reset the status for next validation round\n",
        "#     dice_metric.reset()\n",
        "\n",
        "# print(\"Metric on original image spacing: \", metric_org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpZEVSt7Ou9p"
      },
      "outputs": [],
      "source": [
        "# test_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
        "\n",
        "# test_data = [{\"image\": image} for image in test_images]\n",
        "\n",
        "\n",
        "# test_org_transforms = Compose(\n",
        "#     [\n",
        "#         LoadImaged(keys=\"image\"),\n",
        "#         EnsureChannelFirstd(keys=\"image\"),\n",
        "#         Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "#         Spacingd(keys=[\"image\"], pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
        "#         ScaleIntensityRanged(\n",
        "#             keys=[\"image\"],\n",
        "#             a_min=-57,\n",
        "#             a_max=164,\n",
        "#             b_min=0.0,\n",
        "#             b_max=1.0,\n",
        "#             clip=True,\n",
        "#         ),\n",
        "#         CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# test_org_ds = Dataset(data=test_data, transform=test_org_transforms)\n",
        "\n",
        "# test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "# post_transforms = Compose(\n",
        "#     [\n",
        "#         Invertd(\n",
        "#             keys=\"pred\",\n",
        "#             transform=test_org_transforms,\n",
        "#             orig_keys=\"image\",\n",
        "#             meta_keys=\"pred_meta_dict\",\n",
        "#             orig_meta_keys=\"image_meta_dict\",\n",
        "#             meta_key_postfix=\"meta_dict\",\n",
        "#             nearest_interp=False,\n",
        "#             to_tensor=True,\n",
        "#         ),\n",
        "#         AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
        "#         SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"./out\", output_postfix=\"seg\", resample=False),\n",
        "#     ]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KMxDIzFZ1ob"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "# model.eval()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for test_data in test_org_loader:\n",
        "#         test_inputs = test_data[\"image\"].to(device)\n",
        "#         roi_size = (160, 160, 160)\n",
        "#         sw_batch_size = 4\n",
        "#         test_data[\"pred\"] = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model)\n",
        "\n",
        "#         test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
        "\n",
        "# #         # uncomment the following lines to visualize the predicted results\n",
        "# #         test_output = from_engine([\"pred\"])(test_data)\n",
        "\n",
        "# #         original_image = loader(test_output[0].meta[\"filename_or_obj\"])\n",
        "\n",
        "# #         plt.figure(\"check\", (18, 6))\n",
        "# #         plt.subplot(1, 2, 1)\n",
        "# #         plt.imshow(original_image[:, :, 20], cmap=\"gray\")\n",
        "# #         plt.subplot(1, 2, 2)\n",
        "# #         plt.imshow(test_output[0].detach().cpu()[1, :, :, 20])\n",
        "# #         plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHnjv6LYKw2a"
      },
      "source": [
        "#######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCqfDqhbLX-c"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import CenterSpatialCrop\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        CenterSpatialCrop(roi_size=(96, 96, 96)),  # Adjust the size as needed\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQXsVE3xKzSQ"
      },
      "outputs": [],
      "source": [
        "max_epochs = 10  # Set the number of epochs\n",
        "val_interval = 2  # Interval for validation\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"target\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss /= step\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"target\"].to(device),\n",
        "                )\n",
        "                val_outputs = model(val_inputs)\n",
        "                val_loss += loss_function(val_outputs, val_labels).item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            print(f\"Validation loss: {val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Resize\n",
        "from monai.transforms import LoadImaged, EnsureChannelFirstd, ScaleIntensityRanged, Resized, Compose\n",
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"target\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
        "        Resized(keys=[\"image\",\"target\" ], spatial_size=(96, 96, 96), mode='bilinear'),  # Apply Resized only to \"image\"\n",
        "        # ... other transforms for \"image\" ...\n",
        "    ])\n",
        "\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"target\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
        "        Resized(keys=[\"image\",\"target\"], spatial_size=(96, 96, 96), mode='bilinear'),  # Apply Resized only to \"image\"\n",
        "        # ... other transforms for \"image\" ...\n",
        "    ])\n",
        "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
        "\n",
        "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "LoENt-bzVOVY",
        "outputId": "4d830f65-ee1d-432c-d665-851ad783ebe8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-16c74b2ad5ba>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ... other transforms for \"image\" ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCacheDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CacheDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_data in train_loader:\n",
        "    inputs, targets = batch_data[\"image\"].to(device), batch_data[\"target\"].to(device)\n",
        "    print(\"Inputs shape:\", inputs.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n",
        "    # ... rest of your loop ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "QU2nW2eaXMd0",
        "outputId": "95b7c853-f043-444b-a20f-7e23cbf35565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1336492d245f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inputs shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Targets shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ... rest of your loop ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the necessary imports, data loading, and preprocessing code above this\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,  # Output channel is 1 for regression\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        ").to(device)\n",
        "\n",
        "loss_function = torch.nn.MSELoss()  # Mean Squared Error Loss for regression\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
        "\n",
        "max_epochs = 10\n",
        "val_interval = 2\n",
        "best_metric = float('inf')  # Using MSE, so lower is better\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs = batch_data[\"image\"].to(device)\n",
        "        targets = batch_data[\"target\"].to(device)  # Assuming targets are regression values\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, targets)  # Compare model outputs with regression targets\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs = val_data[\"image\"].to(device)\n",
        "                val_targets = val_data[\"target\"].to(device)\n",
        "                val_outputs = model(val_inputs)\n",
        "                val_loss += loss_function(val_outputs, val_targets).item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            metric_values.append(val_loss)\n",
        "            if val_loss < best_metric:\n",
        "                best_metric = val_loss\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current val loss: {val_loss:.4f}\"\n",
        "                f\"\\nbest val loss: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "yRWwttL2Vn4-",
        "outputId": "8112b212-696a-4c2f-bcfe-e476be96fff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1386: UserWarning: Using a target size (torch.Size([2, 512, 512, 80])) that is different to the input size (torch.Size([2, 1, 96, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3b7045a76ba3>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compare model outputs with regression targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3313\u001b[0m     \"\"\"\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3315\u001b[0;31m         return handle_torch_function(\n\u001b[0m\u001b[1;32m   3316\u001b[0m             \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m         \u001b[0;31m# Use `public_api` instead of `implementation` so __torch_function__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0;31m# implementations can do equality/identity comparisons.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_func_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/data/meta_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;31m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# if \"out\" in kwargs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3328\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (96) must match the size of tensor b (80) at non-singleton dimension 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9goVQ4JYVWg",
        "outputId": "3a6ebae8-c366-43e1-b37f-83cc404219e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs shape: torch.Size([2, 1, 96, 96, 96])\n",
            "Targets shape: torch.Size([2, 512, 512, 80])\n",
            "Inputs shape: torch.Size([2, 1, 96, 96, 96])\n",
            "Targets shape: torch.Size([2, 512, 512, 41])\n",
            "Inputs shape: torch.Size([2, 1, 96, 96, 96])\n",
            "Targets shape: torch.Size([2, 512, 512, 135])\n",
            "Inputs shape: torch.Size([2, 1, 96, 96, 96])\n",
            "Targets shape: torch.Size([2, 512, 512, 101])\n",
            "Inputs shape: torch.Size([1, 1, 96, 96, 96])\n",
            "Targets shape: torch.Size([1, 512, 512, 60])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}