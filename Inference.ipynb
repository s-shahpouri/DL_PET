{"cells":[{"cell_type":"markdown","metadata":{"id":"MXVAKJOVSMyw"},"source":["## Setup environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69702,"status":"ok","timestamp":1705594074527,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"EHBrChiqSMyw","outputId":"9902a3f9-cfa8-4704-fec7-32bcdc3fed4a"},"outputs":[],"source":["\n","from monai.utils import first, set_determinism\n","from monai.transforms import (EnsureChannelFirstd, Compose, CropForegroundd, LoadImaged, Orientationd, RandCropByPosNegLabeld, ScaleIntensityRanged, Spacingd)\n","from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.inferers import sliding_window_inference\n","from monai.data import CacheDataset, DataLoader, Dataset\n","from monai.apps import download_and_extract\n","from monai.transforms import CenterSpatialCropd\n","from monai.transforms import Resized\n","import torch\n","import matplotlib.pyplot as plt\n","import os\n","import glob\n","import torch.nn as nn\n","import json\n","from datetime import datetime\n","from data_preparation2 import DataHandling \n","from UNet_model import create_unet\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25866,"status":"ok","timestamp":1705594100378,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"Xa93Ahdf17k7","outputId":"9fab217d-4e03-4cc6-f83e-165e855c561e"},"outputs":[],"source":["data_dir = '/home/shahpouriz/Data/Practic/ASC-PET-001'\n","directory = '/home/shahpouriz/Data/Practic/LOG'\n","output_dir = '/home/shahpouriz/Data/Practic/OUT'"]},{"cell_type":"markdown","metadata":{"id":"S6t0wW8uSMy4"},"source":["## Set dataset path"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1992,"status":"ok","timestamp":1705594114185,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"5t-z0IfR7w29","outputId":"564adfd1-8f58-4df7-b21c-c625c7b25bc7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/shahpouriz/Data/new_env/lib64/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n"]},{"name":"stdout","output_type":"stream","text":["Starting preparing data ...\n","Loading data from: /home/shahpouriz/Data/Practic/ASC-PET-001\n","Total images loaded: 184\n"]},{"name":"stderr","output_type":"stream","text":["Loading dataset: 100%|██████████| 40/40 [00:51<00:00,  1.29s/it]\n"]}],"source":["# Function to read JSON config file\n","def read_config(config_path):\n","    with open(config_path, 'r') as config_file:\n","        return json.load(config_file)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","print(\"Starting preparing data ...\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","config_path = \"/home/shahpouriz/Data/Practic/training_params.json\"\n","config = read_config(config_path)\n","\n","data_prep = DataHandling(config)\n","loaders, val_files, test_files = data_prep.prepare_data(loaders_to_prepare=[\"test\"])\n","test_loader = loaders.get(\"test\")\n","model = create_unet().to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# check_ds = Dataset(data=test_files, transform=val_transforms)\n","# check_loader = DataLoader(check_ds, batch_size=1)\n","# check_data = first(check_loader)\n","# image, target = (check_data[\"image\"][0][0], check_data[\"target\"][0][0])\n","# print(f\"image shape: {image.shape}, target shape: {target.shape}\")\n","# # plot the slice [:, :, n]\n","# n = 105\n","\n","# plt.figure(\"check\", (12, 6))\n","\n","# plt.subplot(1, 2, 1)\n","# plt.title(\"image\")\n","# # Rotate the image slice and then display it\n","# rotated_image = np.rot90(image[:, n, :])\n","# plt.imshow(rotated_image, cmap=\"gist_yarg\")\n","\n","# plt.subplot(1, 2, 2)\n","# plt.title(\"target\")\n","# # Rotate the target slice and then display it\n","# rotated_target = np.rot90(target[:, n, :])\n","# plt.imshow(rotated_target, cmap='gist_yarg')\n","\n","# plt.show()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1705574741348,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"XNDLov_8fxmU"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1923,"status":"ok","timestamp":1705574748234,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"LpT_08J9sR15","outputId":"f536c4d7-edff-4545-dbd1-92a583870030"},"outputs":[{"name":"stdout","output_type":"stream","text":["Last Best Model Saved as: model_1_24_18_48.pth, Best Metric: 0.1938, Epoch: 230\n"]}],"source":["from utils import find_last_best_model\n","log_filename = 'log_1_24_15_44.txt'\n","log_filepath = directory + '/'+ log_filename\n","bestmodel_filename, best_metric, best_epoch = find_last_best_model(log_filepath)\n","print(f\"Last Best Model Saved as: {bestmodel_filename}, Best Metric: {best_metric}, Epoch: {best_epoch}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":886,"status":"ok","timestamp":1705424528676,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"_4Uhuc7-YuhV","outputId":"3887e3c1-4cc1-4d30-c0db-0c6976d0e9c4"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Function to parse the loss values from the log file\n","def parse_loss_values(log_filepath):\n","    train_losses = []\n","    val_losses = []\n","    with open(log_filepath, 'r') as file:\n","        for line in file:\n","            if 'average loss:' in line:\n","                loss_value = float(line.split(': ')[-1])\n","                train_losses.append(loss_value)\n","            if 'Validation loss:' in line:\n","                val_loss_value = float(line.split(': ')[-1])\n","                val_losses.append(val_loss_value)\n","    return train_losses, val_losses\n","\n","\n","train_losses, val_losses = parse_loss_values(log_filepath)\n","\n","max_epochs = len(train_losses)\n","val_interval = 2  # Update this if your validation interval is different\n","\n","# Plotting\n","plt.figure(figsize=(14, 6))\n","plt.plot(range(1, max_epochs + 1), train_losses, label='Training Loss', color='blue', alpha=0.9)\n","plt.plot(range(2, max_epochs + 1, val_interval), val_losses, label='Validation Loss', color='orange', alpha=0.8)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Losses')\n","plt.legend()\n","plt.xticks(np.arange(1, max_epochs + 1, 20))  # Adjust the x-axis ticks if needed\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3247,"status":"ok","timestamp":1705574758276,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"G4aw_BKdxQxD","outputId":"a12eb0c2-8ab5-4299-c3ca-95c825dcb3a0"},"outputs":[],"source":["import torch\n","\n","\n","def load_model(directory, model_filename):\n","    model_path = os.path.join(directory, model_filename)\n","    if os.path.exists(model_path):\n","        print(f\"Model file {model_filename} is loading.\")\n","        # Load the model onto the CPU\n","        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","    else:\n","        print(f\"Model file {model_filename} not found.\")\n","\n","\n","\n","\n","\n","def find_model_info(log_filepath, model_filename):\n","    best_metric = None\n","    epoch = None\n","    with open(log_filepath, 'r') as file:\n","        for line in file:\n","            if model_filename in line:\n","                parts = line.split(',')\n","                best_metric = float(parts[1].split(': ')[1])  # Extract best metric\n","                epoch = int(parts[2].split(': ')[1])  # Extract epoch number\n","                return model_filename, best_metric, epoch\n","    return model_filename, best_metric, epoch\n","\n","\n","# Usage\n","model_filename_to_find = bestmodel_filename\n","# model_filename_to_find = 'model_1_22_18_3.pth'\n","\n","load_model(directory, model_filename_to_find)\n","\n","bestmodel_filename, best_metric, best_epoch = find_model_info(log_filepath, model_filename_to_find)\n","print(f\"Model: {bestmodel_filename}, Best Metric: {best_metric}, Epoch: {best_epoch}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def visualize_results_whole(test_data, model, n, title):\n","    model.eval()\n","    with torch.no_grad():\n","        test_outputs = model(test_data[\"image\"].to(device))\n","\n","    plt.figure(\"check\", (12, 6))\n","\n","    plt.subplot(1, 3, 1)\n","    plt.title(f\"Input\")\n","    input_slice = np.rot90(test_data[\"image\"][0, 0, :, n, :])\n","    plt.imshow(input_slice, cmap=\"gist_yarg\")\n","\n","    plt.subplot(1, 3, 2)\n","    plt.title(f\"Ground_truth\")\n","    target_slice = np.rot90(test_data[\"target\"][0, 0, :, n, :])\n","    plt.imshow(target_slice, cmap=\"gist_yarg\")\n","\n","    plt.subplot(1, 3, 3)\n","    plt.title(title)\n","    output_slice = np.rot90(test_outputs.detach().cpu()[0, 0, :, n, :])\n","    plt.imshow(output_slice, cmap=\"gist_yarg\")\n","    \n","    plt.show()\n","\n","# Usage\n","with torch.no_grad():\n","    for i, test_data in enumerate(test_loader):\n","        n = 57\n","        visualize_results_whole(test_data, model, n, f\"{bestmodel_filename}\\nepoch: {best_epoch}, best_metric: {best_metric}\")\n","        if i == 2:\n","            break\n"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------\n","# Exporting DL-PET Images\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import nibabel as nib\n","import os\n","import numpy as np\n","import torch\n","\n","def save_nifti(data, filename, affine=np.eye(4)):\n","    nifti_img = nib.Nifti1Image(data, affine)\n","    nib.save(nifti_img, filename)\n","\n","def save_output(test_data, model, output_dir, file_name):\n","    model.eval()\n","    with torch.no_grad():\n","        test_outputs = model(test_data[\"image\"].to(device))\n","\n","    # Loop over each item in the batch\n","    for i in range(len(test_data[\"image\"])):\n","        output_data = test_outputs[i, 0, :, :, :].detach().cpu().numpy()  # Assuming single-channel output\n","        output_file_path = os.path.join(output_dir, f\"DL_{file_name[i]}\")\n","        save_nifti(output_data, output_file_path)\n","\n","\n","\n","with torch.no_grad():\n","    for i, test_data in enumerate(test_loader):\n","        # Extract filenames from test_files\n","        file_names = [os.path.basename(file_info['image']) for file_info in test_files[i*len(test_data[\"image\"]):(i+1)*len(test_data[\"image\"])]]\n","\n","        # Save the output using the modified file names\n","        save_output(test_data, model, output_dir, file_names)\n","        \n","        # Optional: break the loop just for saving a few number of patients\n","        if i == 2:\n","            break\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1JG1lbZwQZ1TZS1EVyy_8ALByR6PaA5EJ","timestamp":1705418268395},{"file_id":"1E8ibC7ZVGwMZwubrqCgHcjS0GUHMG8-T","timestamp":1705308567486}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
