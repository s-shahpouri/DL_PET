{"cells":[{"cell_type":"markdown","metadata":{"id":"MXVAKJOVSMyw"},"source":["## Setup environment"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69702,"status":"ok","timestamp":1705594074527,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"EHBrChiqSMyw","outputId":"9902a3f9-cfa8-4704-fec7-32bcdc3fed4a"},"outputs":[],"source":["\n","from monai.utils import first, set_determinism\n","from monai.transforms import (EnsureChannelFirstd, Compose, CropForegroundd, LoadImaged, Orientationd, RandCropByPosNegLabeld, ScaleIntensityRanged, Spacingd)\n","from monai.networks.nets import UNet\n","from monai.networks.layers import Norm\n","from monai.inferers import sliding_window_inference\n","from monai.data import CacheDataset, DataLoader, Dataset\n","from monai.apps import download_and_extract\n","from monai.transforms import CenterSpatialCropd\n","from monai.transforms import Resized\n","import torch\n","import matplotlib.pyplot as plt\n","import os\n","import glob\n","import torch.nn as nn\n","import json\n","from datetime import datetime\n","from data_preparation2 import DataHandling \n","from UNet_model import create_unet\n","import numpy as np\n","import nibabel as nib"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25866,"status":"ok","timestamp":1705594100378,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"Xa93Ahdf17k7","outputId":"9fab217d-4e03-4cc6-f83e-165e855c561e"},"outputs":[],"source":["data_dir = '/home/shahpouriz/Data/Practic/ASC-PET-001'\n","directory = '/home/shahpouriz/Data/Practic/LOG'\n","output_dir = '/home/shahpouriz/Data/Practic/OUT'"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"calculate_adcm() missing 1 required positional argument: 'asc_img'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nac \u001b[38;5;129;01min\u001b[39;00m train_images:\n\u001b[1;32m     20\u001b[0m     nasc_img \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(nac)\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m---> 23\u001b[0m     adcm \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_adcm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnasc_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     adcm_nii \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mNifti1Image(adcm, affine\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Saving ADCM image\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: calculate_adcm() missing 1 required positional argument: 'asc_img'"]}],"source":["import os\n","import glob\n","import nibabel as nib\n","import numpy as np\n","\n","def calculate_adcm(nasc_img, asc_img, epsilon=1):\n","    adcm = np.where(nasc_img > epsilon, asc_img / nasc_img, asc_img)\n","    return adcm\n","\n","data_dir = '/home/shahpouriz/Data/Practic/ASC-PET-001'\n","adcm_dir = '/home/shahpouriz/Data/Practic/ASC-PET-001/ADCM'  # Directory to save ADCM images\n","\n","if not os.path.exists(adcm_dir):\n","    os.makedirs(adcm_dir)\n","\n","train_images = sorted(glob.glob(os.path.join(data_dir, \"NAC\", \"*.nii.gz\")))\n","target_images = sorted(glob.glob(os.path.join(data_dir, \"MAC\", \"*.nii.gz\")))\n","\n","for nac in train_images:\n","    nasc_img = nib.load(nac).get_fdata()\n","\n","    \n","    adcm = calculate_adcm(nasc_img)\n","    adcm_nii = nib.Nifti1Image(adcm, affine=np.eye(4))\n","\n","    # Saving ADCM image\n","    adcm_filename = os.path.join(adcm_dir, os.path.basename(nac))\n","    nib.save(adcm_nii, adcm_filename)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# New loading process for using ADCM images\n","adcm_images = sorted(glob.glob(os.path.join(adcm_dir, \"*.nii.gz\")))\n","\n","data_dicts = [{\"image\": img, \"target\": tar} for img, tar in zip(adcm_images, target_images)]\n","\n","train_images = sorted(glob.glob(os.path.join(data_dir, \"ADCM\", \"*.nii.gz\")))\n","target_images = sorted(glob.glob(os.path.join(data_dir, \"MAC\", \"*.nii.gz\")))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_files, val_files =  data_dicts[:20], data_dicts[-5:]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"num_samples should be a positive integer value, but got num_samples=0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     14\u001b[0m val_transforms \u001b[38;5;241m=\u001b[39m Compose(\n\u001b[1;32m     15\u001b[0m     [   LoadImaged(keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     16\u001b[0m         EnsureChannelFirstd(keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     25\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m CacheDataset(data\u001b[38;5;241m=\u001b[39mtrain_files, transform\u001b[38;5;241m=\u001b[39mtrain_transforms, cache_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m CacheDataset(data\u001b[38;5;241m=\u001b[39mval_files, transform\u001b[38;5;241m=\u001b[39mval_transforms, cache_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/monai/data/dataloader.py:106\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing_context\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_track_meta()\n\u001b[1;32m     98\u001b[0m ):\n\u001b[1;32m     99\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease be aware: Return type of the dataloader will not be a Tensor as expected but\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a MetaTensor instead! This is because \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m creates a new process where _TRACK_META\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is initialized to True again. Context:_TRACK_META is set to False and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m multiprocessing_context to spawn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:349\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 349\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n","File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/utils/data/sampler.py:140\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"]}],"source":["crop_size = (168, 168, 168)  # Adjusted based on my data\n","\n","train_transforms = Compose(\n","    [   LoadImaged(keys=[\"image\", \"target\"]),\n","        EnsureChannelFirstd(keys=[\"image\", \"target\"]),\n","        # ScaleIntensityRanged(keys=[\"image\", \"target\"],a_min=-60, a_max=120, b_min=0.0, b_max=1.0, clip=True),\n","        # ReferenceBasedNormalizeIntensityd\n","        # Orientationd(keys=[\"image\", \"target\"], axcodes=\"RAS\"),\n","        Spacingd(keys=[\"image\", \"target\"], pixdim=(1.5, 1.5, 2.0)),\n","        Resized(keys=[\"image\", \"target\"], spatial_size=crop_size, mode='bilinear'),\n","        CenterSpatialCropd(keys=[\"image\", \"target\"], roi_size=crop_size),\n","    ])\n","\n","val_transforms = Compose(\n","    [   LoadImaged(keys=[\"image\", \"target\"]),\n","        EnsureChannelFirstd(keys=[\"image\", \"target\"]),\n","        # ScaleIntensityRanged(keys=[\"image\", \"target\"],a_min=-60, a_max=120, b_min=0.0, b_max=1.0, clip=True),\n","        # Orientationd(keys=[\"image\", \"target\"], axcodes=\"RAS\"),\n","        Spacingd(keys=[\"image\", \"target\"], pixdim=(1.5, 1.5, 2.0)),\n","        Resized(keys=[\"image\", \"target\"], spatial_size=crop_size, mode=('bilinear')),\n","        CenterSpatialCropd(keys=[\"image\", \"target\"], roi_size=crop_size),\n","\n","    ])\n","\n","train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=1)\n","train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=1)\n","\n","val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=1)\n","val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=1)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1JG1lbZwQZ1TZS1EVyy_8ALByR6PaA5EJ","timestamp":1705418268395},{"file_id":"1E8ibC7ZVGwMZwubrqCgHcjS0GUHMG8-T","timestamp":1705308567486}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
