{"cells":[{"cell_type":"markdown","metadata":{"id":"MXVAKJOVSMyw"},"source":["## Setup Quantification environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69702,"status":"ok","timestamp":1705594074527,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"EHBrChiqSMyw","outputId":"9902a3f9-cfa8-4704-fec7-32bcdc3fed4a"},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","import os\n","import torch.nn as nn\n","from data_preparation import DataHandling \n","from datetime import datetime\n","import json\n","import numpy as np\n","import os\n","import glob\n","from utils import PairFinder"]},{"cell_type":"markdown","metadata":{"id":"S6t0wW8uSMy4"},"source":["## Set dataset path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config_file = 'config.json'\n","\n","with open(config_file, 'r') as f:\n","    config = json.load(f)\n","\n","ga_data_dir = config[\"ga_data_dir\"]\n","fdg_data_dir = config[\"fdg_data_dir\"]\n","log_dir = config[\"log_dir\"]\n","ga_output_dir = config[\"ga_output_dir\"]\n","artifact_dir = config[\"artifacts\"]\n","artifact_output = config [\"artifact_output\"]\n","fdg_output_dir = config['fdg_output_dir']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# hint = 'dl_dyn3'\n","# hint3 = 'gamodel_3_18_onfdg'\n","# hint = 'gamodel_onfdg'\n","# hint = 'test_corr2'\n","# hint = 'comb_3_27_11_26_onfdg'\n","# hint = 'comb_3_27_11_26_onga'\n","#hint = 'comb_3_27_11_26_onfdg_spacing'\n","# hint = 'dl_dyn1'\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# hint5 = 'comb_3_27_onfdg_v2'\n","# pair_finder_dl3_18 = PairFinder(f'{fdg_data_dir}/MAC', fdg_output_dir, hint5)\n","\n","# hint4 = 'dl_final_3_29_v2'\n","# pair_finder_adcm = PairFinder(f'{fdg_data_dir}/MAC', fdg_output_dir, hint4)\n","# all_pairs_adcm, c5_pairs_adcm, rest_pairs_adcm = pair_finder_adcm.find_file_pairs()\n","# print(len(all_pairs_adcm), len(c5_pairs_adcm), len(rest_pairs_adcm))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hint1 = 'dl3_18' # ga_data_dir  ga_output_dir\n","hint1 = 'dl4_23' # ga_data_dir  ga_output_dir\n","hint1 =  'comb_4_5_onfdg' # fdg_data_dir  fdg_output_dir\n","\n","pair_finder_dl3_18 = PairFinder(f'{fdg_data_dir}/NAC', f'{fdg_data_dir}/MAC', fdg_output_dir, hint1)\n","center_pairs_dyn  = pair_finder_dl3_18.find_file_triples()\n","\n","\n","\n","hint2 = 'dl_final' # ga_data_dir  ga_output_dir\n","hint2 = 'final_4_26' # ga_data_dir  ga_output_dir\n","hint2 = 'final_4_26' # fdg_data_dir  fdg_output_dir\n","\n","pair_finder_adcm = PairFinder(f'{fdg_data_dir}/NAC',f'{fdg_data_dir}/MAC', fdg_output_dir, hint2)\n","center_pairs_adcm  = pair_finder_adcm.find_file_triples()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Delet the empty keys:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["center_pairs_dyn = {center: pairs for center, pairs in center_pairs_dyn.items() if pairs}\n","center_pairs_adcm = {center: pairs for center, pairs in center_pairs_adcm.items() if pairs}\n","\n","center_pairs_adcm"]},{"cell_type":"markdown","metadata":{},"source":["## Normalization Factors:\n","### Ga\n","nac_factor=2, mac_factor=5\n","\n","### FDG\n","nac_factor=3, mac_factor=9"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nac_factor=3; mac_factor=9 # FDG\n","# nac_factor=2; mac_factor=5 # Ga\n","\n","mask_val=0.3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from quant import masked_SUV_img\n","from vis import visualize_coronal_masked\n","\n","# Correctly iterate over pairs within each center group\n","for center, pairs in center_pairs_dyn.items():\n","    for pair in pairs:\n","        # Extract and mask images based on paths stored in 'pair' dictionary\n","        masked_nac_img, masked_predicted_img, masked_reference_img = masked_SUV_img(\n","            pair['nac'], pair['predicted'], pair['reference'], nac_factor, mac_factor, mask_val)\n","        # print(masked_nac_img)\n","        # Visualize a specific slice from the masked images\n","        visualize_coronal_masked(masked_nac_img, masked_predicted_img, masked_reference_img, slice_number=85)  # Adjust slice number as needed\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["------------------\n","# Quantification Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Assuming calculate_metrics_for_pair and your data loading functions are correctly implemented\n","from quant import calculate_metrics_for_pair\n","\n","\n","# Calculate metrics for the ADCM dataset\n","metrics_adcm = []\n","for center, pairs in center_pairs_adcm.items():\n","    for pair in pairs:\n","        metrics = calculate_metrics_for_pair(pair['nac'], pair['predicted'], pair['reference'], nac_factor, mac_factor, mask_val)\n","        metrics['Center'] = center\n","        metrics['Dataset'] = 'ADCM'  # Label this group of metrics\n","        metrics_adcm.append(metrics)\n","\n","# Create DataFrame from ADCM metrics list\n","df_adcm = pd.DataFrame(metrics_adcm)\n","\n","# Calculate metrics for the Multi-center dataset\n","metrics_multi = []\n","for center, pairs in center_pairs_dyn.items():\n","    for pair in pairs:\n","        metrics = calculate_metrics_for_pair(pair['nac'], pair['predicted'], pair['reference'], nac_factor, mac_factor, mask_val)\n","        metrics['Center'] = center\n","        metrics['Dataset'] = 'Multi-Center'  # Label this group of metrics\n","        metrics_multi.append(metrics)\n","\n","# Create DataFrame from Multi-center metrics list\n","df_multi = pd.DataFrame(metrics_multi)\n","\n","# Concatenate both dataframes into a single dataframe\n","df_combined = pd.concat([df_adcm, df_multi])\n","\n","# Display the first few rows of the combined DataFrame\n","df_combined\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_combined.to_csv('Results/metric_data_fdg.csv', index=False)\n","# metric_data_fdg\n","# metric_data_ga"]},{"cell_type":"markdown","metadata":{},"source":["comb_3_27_onfdg:\n","Mean Error (SUV): -0.48 ± 0.1457\n","Mean Absolure Error (SUV): 0.70 ± 0.1316\n","Relative Error (SUV%): -18.30 ± 20.5247\n","Absolure Relative Error (SUV%): 54.24 ± 9.3453\n","Root Mean Squared Error: 1.48 ± 0.8662\n","Peak Signal-to-Noise Ratio: 31.04 ± 5.7015\n","Structual Similarity Index: 0.79 ± 0.0788\n","\n","comb_3_27_onfdg_v2:\n","Mean Error (SUV): -0.04 ± 0.0883\n","Mean Absolure Error (SUV): 0.37 ± 0.0903\n","Relative Error (SUV%): 2.98 ± 10.5086\n","Absolure Relative Error (SUV%): 34.29 ± 9.0125\n","Root Mean Squared Error: 0.71 ± 0.3238\n","Peak Signal-to-Noise Ratio: 38.23 ± 5.6998\n","Structual Similarity Index: 0.92 ± 0.0386\n","\n","\n","dl_final_3_29:\n","Mean Error (SUV): -0.42 ± 0.0783\n","Mean Absolure Error (SUV): 0.42 ± 0.0767\n","Relative Error (SUV%): -72.41 ± 10.2247\n","Absolure Relative Error (SUV%): 72.65 ± 9.9125\n","Root Mean Squared Error: 0.57 ± 0.1856\n","Peak Signal-to-Noise Ratio: 22.53 ± 6.7792\n","Structual Similarity Index: 0.44 ± 0.1617\n","\n","dl_final_3_29_v2: \n","Mean Error (SUV): -0.32 ± 0.1032\n","Mean Absolure Error (SUV): 0.33 ± 0.0868\n","Relative Error (SUV%): -55.49 ± 15.6193\n","Absolure Relative Error (SUV%): 56.98 ± 13.3306\n","Root Mean Squared Error: 0.48 ± 0.1741\n","Peak Signal-to-Noise Ratio: 23.92 ± 6.4356\n","Structual Similarity Index: 0.63 ± 0.1537\n","\n","dl_final_4_26\n","Mean Error (SUV): 0.35 ± 1.9522\n","Mean Absolure Error (SUV): 3.07 ± 1.1359\n","Relative Error (SUV%): -5.89 ± 28.9691\n","Absolure Relative Error (SUV%): 59.33 ± 11.5226\n","Root Mean Squared Error: 12.09 ± 6.8042\n","Peak Signal-to-Noise Ratio: 36.20 ± 4.1976\n","Structual Similarity Index: 0.83 ± 0.1090\n","\n","dl_4_23:\n","comb_3_27_onfdg:\n","Mean Error (SUV): -0.48 ± 0.1457\n","Mean Absolure Error (SUV): 0.70 ± 0.1316\n","Relative Error (SUV%): -18.30 ± 20.5247\n","Absolure Relative Error (SUV%): 54.24 ± 9.3453\n","Root Mean Squared Error: 1.48 ± 0.8662\n","Peak Signal-to-Noise Ratio: 31.04 ± 5.7015\n","Structual Similarity Index: 0.79 ± 0.0788\n","\n","comb_3_27_onfdg_v2:\n","Mean Error (SUV): -0.04 ± 0.0883\n","Mean Absolure Error (SUV): 0.37 ± 0.0903\n","Relative Error (SUV%): 2.98 ± 10.5086\n","Absolure Relative Error (SUV%): 34.29 ± 9.0125\n","Root Mean Squared Error: 0.71 ± 0.3238\n","Peak Signal-to-Noise Ratio: 38.23 ± 5.6998\n","Structual Similarity Index: 0.92 ± 0.0386\n","\n","\n","dl_final_3_29:\n","Mean Error (SUV): -0.42 ± 0.0783\n","Mean Absolure Error (SUV): 0.42 ± 0.0767\n","Relative Error (SUV%): -72.41 ± 10.2247\n","Absolure Relative Error (SUV%): 72.65 ± 9.9125\n","Root Mean Squared Error: 0.57 ± 0.1856\n","Peak Signal-to-Noise Ratio: 22.53 ± 6.7792\n","Structual Similarity Index: 0.44 ± 0.1617\n","\n","dl_final_3_29_v2: \n","Mean Error (SUV): -0.32 ± 0.1032\n","Mean Absolure Error (SUV): 0.33 ± 0.0868\n","Relative Error (SUV%): -55.49 ± 15.6193\n","Absolure Relative Error (SUV%): 56.98 ± 13.3306\n","Root Mean Squared Error: 0.48 ± 0.1741\n","Peak Signal-to-Noise Ratio: 23.92 ± 6.4356\n","Structual Similarity Index: 0.63 ± 0.1537\n","\n","dl_final_4_26\n","Mean Error (SUV): 0.35 ± 1.9522\n","Mean Absolure Error (SUV): 3.07 ± 1.1359\n","Relative Error (SUV%): -5.89 ± 28.9691\n","Absolure Relative Error (SUV%): 59.33 ± 11.5226\n","Root Mean Squared Error: 12.09 ± 6.8042\n","Peak Signal-to-Noise Ratio: 36.20 ± 4.1976\n","Structual Similarity Index: 0.83 ± 0.1090"]},{"cell_type":"markdown","metadata":{},"source":["------------------\n","# Box Plots"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_colors = ['yellowgreen', 'wheat']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","# Define metrics names and titles for the plots\n","metrics_names = ['Mean Error (SUV)', 'Mean Absolure Error (SUV)', 'Relative Error (SUV%)', 'Absolure Relative Error (SUV%)', 'Root Mean Squared Error', 'Peak Signal-to-Noise Ratio', 'Structual Similarity Index']\n","subtitle = ['ME', 'MAE', 'RE(%)', 'ARE(%)', 'RMSE', 'PSNR', 'SSIM']\n","centers = ['Test', 'External']  # 'Test' for C1-C4, 'External' for C5\n","dataset_labels = ['Multi-Center', 'ADCM']  # Labels for datasets\n","dataset_colors = ['cornflowerblue', 'gold']  # Colors for each dataset\n","legend_label = ['IMCM', 'ADCM']\n","# Create patches for the legend\n","patches = [mpatches.Patch(color=color, label=label) for color, label in zip(dataset_colors, legend_label)]\n","\n","# Iterate over each metric and plot data for the grouped test centers and the external center\n","for i, metric in enumerate(metrics_names):\n","    plt.figure(figsize=(4, 3))  # Adjust the size as needed\n","    positions = []\n","    data_to_plot = []\n","\n","    # Collect data for the combined test centers (C1 to C4) and external (C5)\n","    width = 0.2  # Width of the bars in the bar plot\n","    base_gap = 0.1  # Additional gap between dataset pairs within the same group\n","    inter_group_gap = 0.5  # Gap between test and external groups\n","\n","    # Data for test centers\n","    test_data = []\n","    for dataset in dataset_labels:\n","        subset = df_combined[(df_combined['Center'].isin(['C1', 'C2', 'C3', 'C4', 'C6', 'C7'])) & (df_combined['Dataset'] == dataset)][metric]\n","        test_data.append(subset)\n","    data_to_plot.extend(test_data)\n","    positions.extend([1, 1 + width + base_gap])\n","\n","    # Data for external center (C5)\n","    external_data = []\n","    for dataset in dataset_labels:\n","        subset = df_combined[(df_combined['Center'] == 'C5') & (df_combined['Dataset'] == dataset)][metric]\n","        external_data.append(subset)\n","    data_to_plot.extend(external_data)\n","    positions.extend([2 + width + base_gap + inter_group_gap, 2 + 2 * width + 2 * base_gap + inter_group_gap])\n","\n","    # Create the boxplot\n","    bp = plt.boxplot(\n","        data_to_plot,\n","        positions=positions,\n","        widths=width,\n","        patch_artist=True,\n","        medianprops={'color': 'red', 'linewidth': 1}\n","    )\n","\n","    # Set the face color for each box\n","    for box, color in zip(bp['boxes'], dataset_colors * 2):  # Twice for each group\n","        box.set_facecolor(color)\n","\n","    # Custom x-tick labels, aligning them with the respective data groups\n","    plt.xticks([1 + width/2, 2 + width + base_gap + inter_group_gap + width/2], ['Internal', 'External'])\n","\n","    plt.title(f\"{metrics_names[i]}\")\n","    plt.ylabel(subtitle[i])\n","\n","    # Adding the legend to the plot\n","    plt.legend(handles=patches, loc='best')\n","\n","    plt.tight_layout()\n","    plt.show()  # Display the plot\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","# Define metrics names and titles for the plots\n","metrics_names = ['Mean Error (SUV)', 'Mean Absolure Error (SUV)', 'Relative Error (SUV%)', 'Absolure Relative Error (SUV%)', 'Root Mean Squared Error', 'Peak Signal-to-Noise Ratio', 'Structual Similarity Index']\n","subtitle = ['ME', 'MAE', 'RE(%)', 'ARE(%)', 'RMSE', 'PSNR', 'SSIM']\n","centers = df_combined['Center'].unique()  # Extract unique centers\n","dataset_labels = ['Multi-Center', 'ADCM']  # Labels for datasets\n","dataset_colors = ['cornflowerblue', 'gold']  # Colors for each dataset\n","dataset_colors = ['yellowgreen', 'wheat']\n","dataset_colors = ['yellowgreen', 'peachpuff']\n","legend_label = ['TL-MC', 'ADCM']\n","# Create patches for the legend\n","patches = [mpatches.Patch(color=color, label=label) for color, label in zip(dataset_colors, legend_label)]\n","\n","# Iterate over each metric and plot data for all centers and datasets\n","for i, metric in enumerate(metrics_names):\n","    plt.figure(figsize=(5, 4))  # Adjust the size as needed\n","    positions = []\n","    data_to_plot = []\n","\n","    # Collect data for each center and dataset\n","    width = 0.35  # Width of the bars in the bar plot\n","    gap = 0.1  # Additional gap between pairs\n","    for j, center in enumerate(centers):\n","        center_base = j * (3 * width + 2 * gap)  # Adjust base position for each center, spacing them out more\n","        for k, dataset in enumerate(dataset_labels):\n","            subset = df_combined[(df_combined['Center'] == center) & (df_combined['Dataset'] == dataset)][metric]\n","            data_to_plot.append(subset)\n","            positions.append(center_base + k * (width + gap))  # Adjust for width to group datasets together\n","\n","    # Create the boxplot\n","    bp = plt.boxplot(\n","        data_to_plot,\n","        positions=positions,\n","        widths=width,\n","        patch_artist=True,\n","        medianprops={'color': 'red', 'linewidth': 1}\n","    )\n","\n","    # Set the face color for each box\n","    for box, color in zip(bp['boxes'], dataset_colors * len(centers)):\n","        box.set_facecolor(color)\n","\n","    # Custom x-tick labels; position them between groups\n","    center_positions = [(j * (3 * width + 2 * gap) + width ) for j in range(len(centers))]\n","    plt.xticks(center_positions, centers)  # Only center names on x-axis\n","\n","    plt.title(f\"{metrics_names[i]}\")\n","    plt.ylabel(subtitle[i])\n","\n","    # Adding the legend to the plot\n","    plt.legend(handles=patches, loc='best')\n","\n","    plt.tight_layout()\n","    plt.show()  # Display the plot\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","\n","# # Assuming the structure of all_metrics_dl3_18 and all_metrics_adcm as before,\n","# # we prepare the data.\n","\n","# metrics_names = list(all_metrics_dl3_18[0].keys())  # Assuming metric names are the same across datasets\n","# combined_data = {metric: {'dl3_18': [], 'adcm': []} for metric in metrics_names}\n","\n","# for entry in all_metrics_dl3_18:\n","#     for metric, value in entry.items():\n","#         combined_data[metric]['dl3_18'].append(value)\n","\n","# for entry in all_metrics_adcm:\n","#     for metric, value in entry.items():\n","#         combined_data[metric]['adcm'].append(value)\n","\n","# # Now, plot violin plots for each metric.\n","# plt.figure(figsize=(4, 3 * len(metrics_names)))  # Adjust the figure size as needed\n","\n","# subtitle = ['ME','MAE', 'RE(%)', 'ARE(%)', 'RMSE', 'PSNR', 'SSIM']\n","# for i, metric in enumerate(metrics_names, 1):\n","#     plt.subplot(len(metrics_names), 1, i)\n","    \n","#     # Prepare the data for violin plot\n","#     data = [combined_data[metric]['dl3_18'], combined_data[metric]['adcm']]\n","#     plt.boxplot(data)\n","#     # plt.violinplot(data, )\n","    \n","#     # Adding custom x-tick labels\n","#     plt.xticks([1, 2], ['dl3_18', 'adcm'])\n","    \n","#     plt.title(metric)\n","#     plt.ylabel(subtitle[i-1])\n","# plt.tight_layout()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Define your colors for each category\n","# color_palette = ['blue', 'red']  # Choose your colors here\n","\n","# for i, metric in enumerate(metrics):\n","#     plt.figure(figsize=(4, 3))\n","\n","#     # Draw violin plots for each category\n","#     unique_categories = combined_df['dataset'].unique()\n","#     for j, category in enumerate(unique_categories):\n","#         category_data = combined_df[combined_df['dataset'] == category]\n","#         sns.violinplot(x='dataset', y=metric, data=category_data, \n","#                        color=color_palette[j], linewidth=0.2, inner='quartile')\n","\n","#     # Draw box plots for each category\n","#     for j, category in enumerate(unique_categories):\n","#         category_data = combined_df[combined_df['dataset'] == category]\n","#         sns.boxplot(x='dataset', y=metric, data=category_data, showcaps=True, \n","#                     boxprops={'facecolor': 'w'}, showfliers=True, \n","#                     whiskerprops={'linewidth': 2}, width=0.1, color=color_palette[j])\n","\n","#     plt.ylabel(subtitle[i], fontsize=12)\n","#     plt.xlabel('')\n","#     plt.title(f\"{subtitle[i]} ({metric})\", fontsize=14)\n","#     plt.tight_layout()\n","#     plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# import matplotlib.pyplot as plt\n","# import seaborn as sns\n","# from matplotlib.font_manager import FontProperties\n","\n","\n","# # Convert your lists of dictionaries into DataFrames for easier manipulation\n","# df_dl3_18 = pd.DataFrame(all_metrics_dl3_18)\n","# df_adcm = pd.DataFrame(all_metrics_adcm)\n","\n","# # Add a column to each dataframe to label the dataset\n","# df_dl3_18['dataset'] = 'dl3_18'\n","# df_adcm['dataset'] = 'adcm'\n","\n","# # Combine the dataframes\n","# combined_df = pd.concat([df_dl3_18, df_adcm])\n","# legend_font_props = FontProperties()\n","# legend_font_props.set_size('13')\n","# # Now, plot box plots for each metric\n","# metrics = df_dl3_18.columns[:-1]  # Assuming the last column is the 'dataset' label\n","# subtitle = ['ME','MAE', 'RE(%)', 'ARE(%)', 'RMSE', 'PSNR', 'SSIM']\n","# for i, metric in enumerate(metrics):\n","#     plt.figure(figsize=(6, 4))\n","#     # Create the violin plot without splitting by 'hue'\n","#     sns.violinplot(x='dataset', y=metric, data=combined_df, palette='Set1', linewidth=0.5, inner=None)\n","    \n","#     # Create the box plot separately with adjusted width to be narrower\n","#     sns.boxplot(x='dataset', y=metric, data=combined_df, showcaps=False, \n","#                 boxprops={'facecolor': 'None'}, showfliers=False, \n","#                 whiskerprops={'linewidth': 0}, width=0.1)\n","\n","#     plt.ylabel(subtitle[i], fontsize=12)\n","#     plt.xlabel('')\n","#     plt.title(f\"ME (Mean Error (SUV))\", fontsize=14)\n","#     plt.tight_layout()\n","#     plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from quant import calculate_metrics_for_pair, aggregate_metrics\n","# # Calculate metrics for each pair and aggregate results\n","# metrics_c5_adcm = [calculate_metrics_for_pair(\n","#     pair['predicted'], pair['reference'],\n","#     scaling_factor=5, mask_val = 0.3)\n","#     for pair in c5_pairs_adcm]\n","\n","# metrics_rest_adcm = [calculate_metrics_for_pair(\n","#     pair['predicted'], pair['reference'],\n","#     scaling_factor=5, mask_val = 0.3)\n","#     for pair in rest_pairs_adcm]\n","\n","# metrics_c5_dl3_18 = [calculate_metrics_for_pair(\n","#     pair['predicted'], pair['reference'],\n","#     scaling_factor=5, mask_val = 0.3)\n","#     for pair in c5_pairs_dl3_18]\n","\n","# metrics_rest_dl3_18 = [calculate_metrics_for_pair(\n","#     pair['predicted'], pair['reference'],\n","#     scaling_factor=5, mask_val = 0.3)\n","#     for pair in rest_pairs_dl3_18]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# import matplotlib.patches as mpatches\n","\n","\n","# # Assuming that each metric calculation returns a dictionary like before\n","# metrics_names = list(metrics_c5_adcm[0].keys())  # Metric names from the data\n","# subtitle = ['ME', 'MAE', 'RE(%)', 'ARE(%)', 'RMSE', 'PSNR', 'SSIM']\n","# colors = ['cornflowerblue', 'gold']  # Colors for c5s and rests\n","# # 'lightblue', 'lightcoral'\n","\n","\n","# for i, metric in enumerate(metrics_names):\n","#     plt.figure(figsize=(5, 3))  # Adjust the figure size\n","    \n","#     # Prepare data for c5s and rests for both datasets\n","#     data_c5_adcm = [entry[metric] for entry in metrics_c5_adcm]\n","#     data_rest_adcm = [entry[metric] for entry in metrics_rest_adcm]\n","#     data_c5_dl3_18 = [entry[metric] for entry in metrics_c5_dl3_18]\n","#     data_rest_dl3_18 = [entry[metric] for entry in metrics_rest_dl3_18]\n","    \n","#     # Create boxplots\n","#     positions = [1, 2, 4, 5]  # Position for each boxplot\n","#     data = [data_c5_dl3_18, data_rest_dl3_18, data_c5_adcm, data_rest_adcm]\n","#     boxplot_parts = plt.boxplot(data, positions=positions, patch_artist=True,\n","#                                 medianprops={'color': 'r', 'linewidth': 1})\n","    \n","#     # Set colors for each boxplot\n","#     for patch, position in zip(boxplot_parts['boxes'], positions):\n","#         color = colors[0] if position in [1, 4] else colors[1]\n","#         patch.set_facecolor(color)\n","    \n","#     # Custom x-tick labels\n","#     plt.xticks([1.5, 4.5], ['DL3_18', 'ADCM'])\n","#         # Create custom legend patches\n","    \n","#     rest_patch = mpatches.Patch(color=colors[0], label='Internal')\n","#     c5_patch = mpatches.Patch(color=colors[1], label='External')\n","\n","\n","#     # Add legend to the plot\n","#     plt.legend(handles=[c5_patch, rest_patch], loc='upper center')\n","#     plt.title(metrics_names[i])\n","#     plt.ylabel(subtitle[i])\n","    \n","#     plt.tight_layout()\n","#     plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["-----------------"]},{"cell_type":"markdown","metadata":{},"source":["# Joint Histogram"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from scipy.stats import linregress\n","# values_predicted_imcm = []\n","# values_reference_imcm= []\n","\n","# for center, pairs in center_pairs_dyn.items():\n","#     for pair in pairs:\n","#         masked_nac_img, masked_predicted_img, masked_reference_img = masked_SUV_img(\n","#             pair['nac'], pair['predicted'], pair['reference'], nac_factor=2, mac_factor=5, mask_val=0.3)\n","#         predicted_flat = masked_predicted_img.ravel()\n","#         reference_flat = masked_reference_img.ravel()\n","#         values_predicted_imcm.extend(predicted_flat)\n","#         values_reference_imcm.extend(reference_flat)\n","\n","\n","# values_predicted_adcm = []\n","# values_reference_adcm= []\n","# for center, pairs in center_pairs_adcm.items():\n","#     for pair in pairs:\n","#         masked_nac_img, masked_predicted_img, masked_reference_img = masked_SUV_img(\n","#             pair['nac'], pair['predicted'], pair['reference'], nac_factor=2, mac_factor=5, mask_val=0.3)\n","#         predicted_flat = masked_predicted_img.ravel()\n","#         reference_flat = masked_reference_img.ravel()\n","#         values_predicted_adcm.extend(predicted_flat)\n","#         values_reference_adcm.extend(reference_flat)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from scipy.stats import linregress\n","import numpy as np\n","\n","def plot_joint_histogram(reference, predicted, ax, title, max_val, mask):\n","    reference = np.array(reference)\n","    predicted = np.array(predicted)\n","\n","    # Apply a filtering threshold\n","    mask = predicted < mask\n","    reference_filtered = reference[mask]\n","    predicted_filtered = predicted[mask]\n","\n","    # Plotting\n","    hexbin = ax.hexbin(reference_filtered, predicted_filtered, gridsize=300, cmap='rainbow', bins='log', mincnt=2)\n","    plt.colorbar(hexbin, ax=ax)\n","\n","    # Add a bisector line\n","    ax.plot([0, max_val], [0, max_val], 'k--', alpha =0.5)\n","    # Regression analysis on the filtered data\n","    if len(reference_filtered) > 1:\n","        slope, intercept, r_value, _, _ = linregress(reference_filtered, predicted_filtered)\n","        ax.plot(reference_filtered, intercept + slope * reference_filtered, 'w--', label=f'y = {slope:.2f}x + {intercept:.2f}\\nR={r_value:.3f}', alpha = 0.8)\n","\n","    ax.set_xlabel('Reference (SUV)')\n","    ax.set_ylabel('Predicted (SUV)')\n","    ax.set_title(title)\n","    ax.legend(loc=\"lower right\")\n","\n","def prepare_and_plot_data(pairs, dataset_label, ax, max_val):\n","    values_predicted = []\n","    values_reference = []\n","    for pair in pairs:\n","        # Assuming 'masked_SUV_img' is a function that properly masks your images\n","        _, masked_predicted_img, masked_reference_img = masked_SUV_img(\n","            pair['nac'], pair['predicted'], pair['reference'], nac_factor=2, mac_factor=5, mask_val=0.3)\n","        values_predicted.extend(masked_predicted_img.ravel())\n","        values_reference.extend(masked_reference_img.ravel())\n","\n","    plot_joint_histogram(values_reference, values_predicted, ax, f'{dataset_label}', max_val, mask)\n","\n","mask = 1000\n","centers = ['C1', 'C2', 'C3', 'C4', 'C5']  # Example list of centers\n","# max_val = 350  # Define a maximum value for threshold\n","\n","for center in centers:\n","    fig, axs = plt.subplots(1, 2, figsize=(9, 4), sharey=False, sharex=False)\n","    prepare_and_plot_data(center_pairs_dyn[center], 'IMCM', axs[0], max_val=350)\n","    prepare_and_plot_data(center_pairs_adcm[center], 'ADCM', axs[1], max_val=350)\n","    plt.suptitle(f'Joint Histogram Analysis - Center {center}')\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from scipy.stats import gaussian_kde\n","# from scipy.stats import linregress\n","\n","# def create_density_scatter_plot(suv_predicted, suv_reference, dataset_label, sample_size=None):\n","#     # Ensure the data is in the form of 1D NumPy arrays\n","#     suv_predicted = np.asarray(suv_predicted).flatten()\n","#     suv_reference = np.asarray(suv_reference).flatten()\n","\n","#     # Sample the data to speed up the process if needed\n","#     if sample_size is not None and len(suv_predicted) > sample_size:\n","#         idx = np.random.choice(len(suv_predicted), size=sample_size, replace=False)\n","#         suv_predicted = suv_predicted[idx]\n","#         suv_reference = suv_reference[idx]\n","\n","#     # Calculate the point density using Gaussian KDE\n","#     xy = np.vstack([suv_reference, suv_predicted])\n","#     z = gaussian_kde(xy)(xy)\n","    \n","#     # Sort the points by density, so the densest points are plotted last\n","#     idx = z.argsort()\n","#     suv_reference, suv_predicted, z = suv_reference[idx], suv_predicted[idx], z[idx]\n","    \n","#     # Calculate regression line and R-squared value\n","#     slope, intercept, r_value, p_value, std_err = linregress(suv_reference, suv_predicted)\n","#     regression_line = slope * suv_reference + intercept\n","\n","#     # Create the scatter plot\n","#     plt.figure(figsize=(8, 6))\n","#     scatter = plt.scatter(suv_reference, suv_predicted, c=z, s=10, cmap='rainbow')\n","#     plt.colorbar(scatter, label='Density')\n","#     plt.plot(suv_reference, regression_line, color='black', linestyle='dashed', linewidth=1)\n","#     plt.title(f'{dataset_label} Density Scatter Plot')\n","#     plt.xlabel('Reference SUV')\n","#     plt.ylabel('Predicted SUV')\n","\n","#     # Annotation for regression line equation and R-squared\n","#     plt.annotate(f'y = {slope:.2f}x + {intercept:.2f}\\n$R^2$ = {r_value**2:.3f}', xy=(0.05, 0.95), xycoords='axes fraction', ha='left', va='top', fontsize=12, color='white')\n","\n","#     # Show plot\n","#     plt.show()\n","\n","# # Replace with your actual data\n","# create_density_scatter_plot(suv_predicted_adcm, suv_reference_adcm, 'ADCM', sample_size=500000)\n","# create_density_scatter_plot(suv_predicted_dl3_18, suv_reference_dl3_18, 'DL3_18', sample_size=500000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from scipy.stats import gaussian_kde\n","# from scipy.stats import linregress\n","\n","# def create_density_scatter_plot(suv_predicted, suv_reference, dataset_label):\n","#     # Calculate the point density\n","#     xy = np.vstack([suv_reference, suv_predicted])\n","#     z = gaussian_kde(xy)(xy)\n","\n","#     # Sort the points by density, so that the densest points are plotted last\n","#     idx = z.argsort()\n","#     suv_reference, suv_predicted, z = suv_reference[idx], suv_predicted[idx], z[idx]\n","    \n","#     # Calculate regression line and R-squared value\n","#     slope, intercept, r_value, _, _ = linregress(suv_reference, suv_predicted)\n","#     regression_line = slope * suv_reference + intercept\n","\n","#     # Create the density scatter plot\n","#     plt.figure(figsize=(8, 6))\n","#     scatter = plt.scatter(suv_reference, suv_predicted, c=z, s=50, edgecolor='', cmap='rainbow')\n","#     plt.colorbar(scatter, label='Density')\n","    \n","#     # Plot regression line\n","#     plt.plot(suv_reference, regression_line, color='red', linestyle='dashed', linewidth=2)\n","\n","#     # Annotations for regression line equation and R-squared\n","#     plt.annotate(f'y = {slope:.2f}x + {intercept:.2f}\\n$R^2$ = {r_value**2:.3f}',\n","#                  xy=(0.05, 0.95), xycoords='axes fraction', \n","#                  ha='left', va='top', color='red', fontsize=12,\n","#                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n","\n","#     # Set labels and title\n","#     plt.xlabel('Reference SUV')\n","#     plt.ylabel('Predicted SUV')\n","#     plt.title(f'Density Scatter Plot for {dataset_label}')\n","\n","#     # Show the plot\n","#     plt.show()\n","\n","# # Generate and show density scatter plots for both datasets\n","# create_density_scatter_plot(suv_predicted_adcm, suv_reference_adcm, 'ADCM')\n","# create_density_scatter_plot(suv_predicted_dl3_18, suv_reference_dl3_18, 'DL3_18')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# # Plot using seaborn's regplot, which includes a regression line and 95% CI by default\n","# plt.figure(figsize=(8, 6))\n","# ax = sns.regplot(x=suv_reference_adcm, y=suv_predicted_adcm, ci=95, color='b', scatter_kws={'alpha':0.3})\n","\n","# # You can set the facecolor of the axes to match the lowest color in the colormap\n","# ax.set_facecolor('#280137')  # Adjust the color code to match your colormap's lowest value\n","\n","# # Labels and title\n","# plt.xlabel('Reference SUV')\n","# plt.ylabel('Predicted SUV')\n","# plt.title('Regression Analysis with 95% CI')\n","\n","# # Show the plot\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","\n","# Calculate regression values\n","slope, intercept, r_value, p_value, std_err = stats.linregress(suv_reference_adcm, suv_predicted_adcm)\n","\n","# Define a function for the regression line\n","def predict(x):\n","    return slope * x + intercept\n","\n","# Predict values along the regression line\n","line = predict(suv_reference_adcm)\n","\n","# Calculate the confidence interval\n","confidence_level = 0.95\n","degrees_freedom = len(suv_reference_adcm) - 2\n","t_critical = np.abs(stats.t.ppf((1 - confidence_level) / 2, degrees_freedom))\n","s_err = np.sum((suv_predicted_adcm - line)**2) / degrees_freedom\n","conf_interval = t_critical * np.sqrt((s_err/(len(suv_reference_adcm)-1))*(1 + (suv_reference_adcm-np.mean(suv_reference_adcm))**2/np.sum((suv_reference_adcm-np.mean(suv_reference_adcm))**2)))\n","\n","# Plot the data\n","plt.figure(figsize=(8, 6))\n","plt.scatter(suv_reference_adcm, suv_predicted_adcm, alpha=0.5)\n","plt.plot(suv_reference_adcm, line, color='red', label=f'Linear Regression\\n$y = {slope:.2f}x + {intercept:.2f}$\\n$R^2 = {r_value**2:.3f}$')\n","\n","# Fill the confidence interval\n","plt.fill_between(suv_reference_adcm, line - conf_interval, line + conf_interval, color='red', alpha=0.2, label='95% Confidence Interval')\n","\n","# Set the background color\n","plt.gca().set_facecolor('#280137')\n","\n","# Labels and title\n","plt.xlabel('Reference SUV')\n","plt.ylabel('Predicted SUV')\n","plt.title('Regression Analysis with 95% CI')\n","plt.legend()\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Results for Dynunet without matching the networks prameters:\n","mean_error: -0.25 ± 0.0722\n","mean_absolute_error: 0.43 ± 0.0803\n","relative_error: 7.56 ± 7.7195\n","absolute_relative_error: 38.52 ± 4.3638\n","rmse: 2.10 ± 0.9815\n","psnr: 39.60 ± 3.0782\n","ssim: 0.97 ± 0.0040\n","\n","\n","# Results for Dyunet with matching the networks prameters:\n","\n","mean_error: -0.27 ± 0.0802\n","mean_absolute_error: 0.37 ± 0.0524\n","relative_error: -14.82 ± 2.6155\n","absolute_relative_error: 35.17 ± 3.3576\n","rmse: 1.60 ± 0.3624\n","psnr: 41.57 ± 2.2030\n","ssim: 0.97 ± 0.0056\n","\n","\n","# Resulats for Dyunet after some augmentation:\n","\n","mean_error: -0.13 ± 0.1053\n","mean_absolute_error: 0.29 ± 0.1097\n","relative_error: 11.28 ± 9.1598\n","absolute_relative_error: 24.58 ± 7.9870\n","rmse: 1.59 ± 0.9717\n","psnr: 43.46 ± 4.1015\n","ssim: 0.98 ± 0.0063"]},{"cell_type":"markdown","metadata":{},"source":["# Results for re-trained model with fdg data on fdg datatest\n","mean_error: 0.02 ± 0.0064\n","mean_absolute_error: 0.08 ± 0.0111\n","relative_error: 6.71 ± 0.0923\n","absolute_relative_error: 10.90 ± 0.1017\n","rmse: 0.30 ± 0.0762\n","psnr: 46.35 ± 6.6213\n","ssim: 0.98 ± 0.0056"]}],"metadata":{"colab":{"provenance":[{"file_id":"1JG1lbZwQZ1TZS1EVyy_8ALByR6PaA5EJ","timestamp":1705418268395},{"file_id":"1E8ibC7ZVGwMZwubrqCgHcjS0GUHMG8-T","timestamp":1705308567486}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
