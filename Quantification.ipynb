{"cells":[{"cell_type":"markdown","metadata":{"id":"MXVAKJOVSMyw"},"source":["## Setup environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69702,"status":"ok","timestamp":1705594074527,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"EHBrChiqSMyw","outputId":"9902a3f9-cfa8-4704-fec7-32bcdc3fed4a"},"outputs":[],"source":["\n","from monai.utils import first, set_determinism\n","import torch\n","import matplotlib.pyplot as plt\n","import os\n","import torch.nn as nn\n","from data_preparation import DataHandling \n","from datetime import datetime\n","import json\n","import numpy as np\n"]},{"cell_type":"markdown","metadata":{"id":"S6t0wW8uSMy4"},"source":["## Set dataset path"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["config_file = 'config.json'\n","\n","with open(config_file, 'r') as f:\n","    config = json.load(f)\n","\n","ga_data_dir = config[\"ga_data_dir\"]\n","fdg_data_dir = config[\"fdg_data_dir\"]\n","log_dir = config[\"log_dir\"]\n","output_dir = config[\"output_dir\"]\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","import glob\n","from utils import PairFinder\n","# hint = 'dl_dyn3'\n","# hint = 'gamodel_3_18_onfdg'\n","# hint = 'gamodel_onfdg'\n","# hint = 'test_corr2'\n","# hint = 'comb_3_27_11_26_onfdg'\n","# hint = 'comb_3_27_11_26_onga'\n","#hint = 'comb_3_27_11_26_onfdg_spacing'\n","hint = 'dl_dyn1'\n","pair_finder = PairFinder(f'{ga_data_dir}/MAC', output_dir, hint)\n","pair_finder = PairFinder(f'{ga_data_dir}/MAC', output_dir, hint)\n","all_pairs, c5_pairs, rest_pairs = pair_finder.find_file_pairs()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# import nibabel as nib\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# def load_nifti_image(path):\n","#     \"\"\"Load a NIfTI image and return its data as a NumPy array.\"\"\"\n","#     return nib.load(path).get_fdata()\n","\n","# def create_mask_from_reference(reference_img, mask_threshold=0.03, scaling_factor=5):\n","#     \"\"\"Create a mask from the reference image based on a threshold.\"\"\"\n","#     scaled_reference_img = reference_img * scaling_factor\n","#     mask = scaled_reference_img > mask_threshold\n","#     return mask\n","\n","# def apply_mask(image, mask, scaling_factor=5):\n","#     \"\"\"Apply the mask to the image.\"\"\"\n","#     scaled_image = image * scaling_factor\n","#     masked_image = np.zeros_like(scaled_image)\n","#     masked_image[mask] = scaled_image[mask]\n","#     return masked_image\n","\n","\n","# def plot_coronal_slice(img, title=\"Image slice\", cmap=\"jet\", slice_idx=None):\n","#     \"\"\"Plots a coronal slice of an image.\"\"\"\n","#     if slice_idx is None:\n","#         slice_idx = 70  \n","#     plt.figure()\n","#     plt.imshow(img[:, slice_idx, :], cmap=cmap, origin='lower')\n","#     plt.title(title)\n","#     plt.axis(\"off\")\n","#     plt.show()\n","\n","# # Loop through each pair of images in the list\n","# for pair in test_dict_list:\n","#     predicted_img_path = pair['predicted']\n","#     reference_img_path = pair['reference']\n","    \n","#     # Load the images\n","#     predicted_img = load_nifti_image(predicted_img_path)\n","#     reference_img = load_nifti_image(reference_img_path)\n","    \n","#     # Create a mask from the reference image\n","#     mask = create_mask_from_reference(reference_img)\n","    \n","#     # Apply the same mask to both images\n","#     masked_predicted_img = apply_mask(predicted_img, mask)\n","#     masked_reference_img = apply_mask(reference_img, mask)\n","    \n","  \n","#     # # Plot a coronal slice for both masked images\n","#     # plot_coronal_slice(masked_predicted_img, title=f\"Masked Predicted: {predicted_img_path.split('/')[-1]}\")\n","#     # plot_coronal_slice(masked_reference_img, title=f\"masked Reference: {reference_img_path.split('/')[-1]}\")\n","\n","#     # plot_coronal_slice(reference_img, title=f\"unmasked Reference: {reference_img_path.split('/')[-1]}\")\n","\n","#     break\n","    "]},{"cell_type":"markdown","metadata":{},"source":["------------------\n","# Quantification Evaluation"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np\n","import nibabel as nib\n","from math import sqrt, log10\n","from skimage.metrics import structural_similarity as ssim\n","\n","def mean_error(predicted, reference):\n","    return np.mean(predicted - reference)\n","\n","def mean_absolute_error(predicted, reference):\n","    return np.mean(np.abs(predicted - reference))\n","\n","def relative_error(predicted, reference):\n","\n","    re = np.mean((predicted - reference) / (reference )) * 100\n","    return re\n","\n","def absolute_relative_error(predicted, reference):\n","    # Create a mask for pixels in the reference image above the threshold\n","\n","    # Calculate the absolute relative error using the masked pixels\n","    are = np.mean(np.abs(predicted - reference) / reference) * 100\n","    \n","    return are\n","\n","def rmse(predicted, reference):\n","    return sqrt(np.mean((predicted - reference) ** 2))\n","\n","def psnr(predicted, reference, peak):\n","    mse = np.mean((predicted - reference) ** 2)\n","    return 20 * log10(peak / sqrt(mse))\n","\n","def calculate_ssim(predicted, reference):\n","    return ssim(predicted, reference, data_range=reference.max() - reference.min())\n","\n","def load_nifti_image(path):\n","    \"\"\"Load a NIfTI image and return its data as a NumPy array.\"\"\"\n","    return nib.load(path).get_fdata()\n","\n","def calculate_metrics_for_pair(predicted_path, reference_path, scaling_factor, mask_val):\n","    \"\"\"\n","    Calculate metrics for a single pair of images, applying a scaling factor to the images.\n","    A mask is applied where the reference image values are bigger than 0.03.\n","    \"\"\"\n","    predicted_img = load_nifti_image(predicted_path) * scaling_factor\n","    reference_img = load_nifti_image(reference_path) * scaling_factor\n","    # print(np.min(predicted_img), np.max(predicted_img))\n","    # print(np.min(reference_img), np.max(reference_img))\n","    # print(\"---------------------------------------------\")\n","    # Create mask from reference image where values are greater than 0.03\n","    mask = reference_img > mask_val\n","    \n","    # Apply the mask to both images\n","    masked_predicted_img = predicted_img[mask]\n","    masked_reference_img = reference_img[mask]\n","\n","    peak = np.max([masked_predicted_img.max(), masked_reference_img.max()])\n","    metrics = {\n","        \"mean_error\": mean_error(masked_predicted_img, masked_reference_img),\n","        \"mean_absolute_error\": mean_absolute_error(masked_predicted_img, masked_reference_img),\n","        \"relative_error\": relative_error(masked_predicted_img, masked_reference_img),\n","        \"absolute_relative_error\": absolute_relative_error(masked_predicted_img, masked_reference_img),\n","        \"rmse\": rmse(masked_predicted_img, masked_reference_img),\n","        \"psnr\": psnr(masked_predicted_img, masked_reference_img, peak),\n","        \"ssim\": calculate_ssim(masked_predicted_img, masked_reference_img)\n","    }\n","    return metrics\n","\n","def aggregate_metrics(metrics_list):\n","    \"\"\"Aggregate metrics across all pairs and calculate mean and standard deviation.\"\"\"\n","    aggregated_metrics = {key: [] for key in metrics_list[0]}\n","    for metrics in metrics_list:\n","        for key, value in metrics.items():\n","            aggregated_metrics[key].append(value)\n","    \n","    return {metric: (np.mean(values), np.std(values)) for metric, values in aggregated_metrics.items()}"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mean_error: -0.42 ± 0.7114\n","mean_absolute_error: 1.30 ± 0.3018\n","relative_error: 2.88 ± 16.0516\n","absolute_relative_error: 35.94 ± 5.5011\n","rmse: 3.48 ± 1.7411\n","psnr: 37.04 ± 1.8921\n","ssim: 0.94 ± 0.0325\n"]}],"source":["# from utils import calculate_metrics_for_pair, aggregate_metrics\n","\n","# Calculate metrics for each pair and aggregate results\n","all_metrics = [calculate_metrics_for_pair(\n","    pair['predicted'], pair['reference'],\n","    scaling_factor=5, mask_val = 0.3)\n","    for pair in rest_pairs]\n","\n","metric_means_sds = aggregate_metrics(all_metrics)\n","\n","# Print aggregated metrics\n","for metric, (mean, sd) in metric_means_sds.items():\n","    print(f\"{metric}: {mean:.2f} ± {sd:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Masked Predicted: [0.1 0.2 0.4]\n","Masked Reference: [0.15 0.25 0.35]\n"]}],"source":["import numpy as np\n","\n","# Example data\n","predicted = np.array([0.1, 0.2, 1.05, 0.4])\n","reference = np.array([0.15, 0.25, 0.02, 0.35])\n","\n","# Threshold\n","threshold = 0.03\n","\n","# Mask where reference values are greater than the threshold\n","mask = reference > threshold\n","\n","# Applying the mask\n","masked_predicted = predicted[mask]\n","masked_reference = reference[mask]\n","\n","# Original data becomes subset\n","print(\"Masked Predicted:\", masked_predicted)\n","print(\"Masked Reference:\", masked_reference)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Results for Dynunet without matching the networks prameters:\n","mean_error: -0.25 ± 0.0722\n","mean_absolute_error: 0.43 ± 0.0803\n","relative_error: 7.56 ± 7.7195\n","absolute_relative_error: 38.52 ± 4.3638\n","rmse: 2.10 ± 0.9815\n","psnr: 39.60 ± 3.0782\n","ssim: 0.97 ± 0.0040\n","\n","\n","# Results for Dyunet with matching the networks prameters:\n","\n","mean_error: -0.27 ± 0.0802\n","mean_absolute_error: 0.37 ± 0.0524\n","relative_error: -14.82 ± 2.6155\n","absolute_relative_error: 35.17 ± 3.3576\n","rmse: 1.60 ± 0.3624\n","psnr: 41.57 ± 2.2030\n","ssim: 0.97 ± 0.0056\n","\n","\n","# Resulats for Dyunet after some augmentation:\n","\n","mean_error: -0.13 ± 0.1053\n","mean_absolute_error: 0.29 ± 0.1097\n","relative_error: 11.28 ± 9.1598\n","absolute_relative_error: 24.58 ± 7.9870\n","rmse: 1.59 ± 0.9717\n","psnr: 43.46 ± 4.1015\n","ssim: 0.98 ± 0.0063"]},{"cell_type":"markdown","metadata":{},"source":["# Results for re-trained model with fdg data on fdg datatest\n","mean_error: 0.02 ± 0.0064\n","mean_absolute_error: 0.08 ± 0.0111\n","relative_error: 6.71 ± 0.0923\n","absolute_relative_error: 10.90 ± 0.1017\n","rmse: 0.30 ± 0.0762\n","psnr: 46.35 ± 6.6213\n","ssim: 0.98 ± 0.0056"]}],"metadata":{"colab":{"provenance":[{"file_id":"1JG1lbZwQZ1TZS1EVyy_8ALByR6PaA5EJ","timestamp":1705418268395},{"file_id":"1E8ibC7ZVGwMZwubrqCgHcjS0GUHMG8-T","timestamp":1705308567486}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
