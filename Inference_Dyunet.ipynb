{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69702,"status":"ok","timestamp":1705594074527,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"EHBrChiqSMyw","outputId":"9902a3f9-cfa8-4704-fec7-32bcdc3fed4a"},"outputs":[],"source":["\n","from monai.transforms import (Compose)\n","from monai.inferers import sliding_window_inference\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from monai.transforms import Compose, Invertd, SaveImaged\n","from monai.inferers import sliding_window_inference\n","from monai.data import decollate_batch\n","import torch\n","import json\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25866,"status":"ok","timestamp":1705594100378,"user":{"displayName":"Samaneh Shahpuori","userId":"07452399669550385873"},"user_tz":-60},"id":"Xa93Ahdf17k7","outputId":"9fab217d-4e03-4cc6-f83e-165e855c561e"},"outputs":[],"source":["config_file = 'config.json'\n","\n","with open(config_file, 'r') as f:\n","    config = json.load(f)\n","\n","ga_data_dir = config[\"ga_data_dir\"]\n","fdg_data_dir = config[\"fdg_data_dir\"]\n","log_dir = config[\"log_dir\"]\n","output_dir = config[\"output_dir\"]\n","artifact_dir = config[\"artifacts\"]\n","artifact_output = config [\"artifact_output\"]\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["131\n","33\n","20\n"]}],"source":["from data_preparation import DataHandling \n","\n","data_handler = DataHandling(ga_data_dir, train_mode=\"NAC\", target_mode=\"MAC\")\n","\n","train_files = data_handler.get_data_split('train')\n","val_files = data_handler.get_data_split('val')\n","test_files = data_handler.get_data_split('test')\n","print(len(train_files))\n","print(len(val_files))\n","print(len(test_files))\n","\n","from data_preparation import LoaderFactory\n","loader_factory = LoaderFactory(\n","    train_files=train_files,\n","    val_files=val_files,\n","    test_files=test_files,\n","    patch_size = [168, 168, 16],\n","    spacing = [4.07, 4.07, 3.00],\n","    # spacing = [1.92, 1.92, 3.27], # For fdg data\n","    spatial_size = (168, 168, 320)\n","    # spatial_size = (336, 336, 640) # for Fdg data\n","    )\n","\n","test_loader = loader_factory.get_loader('test', batch_size=1, num_workers=2, shuffle=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from data_preparation import ExtrenalRadioSetSetHandling\n","\n","# data_handler = ExtrenalRadioSetSetHandling(artifact_dir, train_mode=\"NAC\", target_mode=\"MAC\")\n","\n","# test_files = data_handler.get_data()\n","# print(len(test_files))\n","\n","# from data_preparation import LoaderFactory\n","# loader_factory = LoaderFactory(\n","#     # train_files=train_files,\n","#     # val_files=val_files,\n","#     test_files=test_files,\n","#     patch_size = [168, 168, 16],\n","#     spacing = [4.07, 4.07, 3.00],\n","#     spatial_size = (168, 168, 480)\n","#     )\n","\n","# # Get the DataLoader for each dataset type\n","# # train_loader = loader_factory.get_loader('train', batch_size=4, num_workers=2, shuffle=True)\n","# # val_loader = loader_factory.get_loader('val', batch_size=1, num_workers=2, shuffle=False)\n","# test_loader = loader_factory.get_loader('test', batch_size=1, num_workers=2, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from monai.transforms import LoadImage\n","\n","# # Assuming 'test_files' contains your image paths like {'image': 'path/to/image.nii', 'target': 'path/to/target.nii'}\n","# loader = LoadImage(image_only=True)\n","\n","# for i in test_files:\n","#     image_path = i['image']  # Replace 'test_files[0]['image']' with the actual path if necessary\n","#     original_image = loader(image_path)\n","#     print(f\"Original image size: {original_image.shape}\")\n","\n","# print('--------------------------')\n","# for batch in test_loader:\n","#     transformed_image = batch['image']\n","#     print(f\"Transformed image size: {transformed_image.shape}\")\n","#       # Break after the first batch since you're only interested in one image\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data_preparation import visualize_axial_slice, visualize_axial_slice2\n","\n","\n","slice_index = 100  # Example slice index.\n","visualize_axial_slice2(test_loader, slice_index)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["slice_index = 200  # Example slice index.\n","visualize_axial_slice(test_loader, slice_index)\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Filename: model_3_18_22_10.pth, Best Metric: 0.0664, Epoch: 298\n"]}],"source":["from utils import find_last_saved_model, parse_loss_values\n","\n","# log_filename = 'log_2_26_8_17.txt'\n","# log_filename = 'log_3_4_12_4.txt'\n","# log_filename = 'log_3_4_12_41.txt'\n","log_filename = 'log_3_18.txt'\n","# log_filename = 'log_3_27_8_47.txt'\n","# log_filename = 'log_3_28_10_41.txt'\n","# log_filename = 'log_3_28_20_48.txt'\n","# log_filename = 'log_3_29_6_54.txt'\n","# log_filename = 'log_4_6_8_55.txt'\n","# log_filename = 'log_4_6_8_55.txt'\n","\n","log_filepath = log_dir + '/'+ log_filename\n","bestmodel_filename, best_metric, best_epoch = find_last_saved_model(log_filepath)\n","print(f\"Model Filename: {bestmodel_filename}, Best Metric: {best_metric}, Epoch: {best_epoch}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# bestmodel_filename =  'model_4_2_0_41.pth'\n","\n","# best_metric = 0.3338\n","# best_epoch = 38"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1400x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train_losses, val_losses = parse_loss_values(log_filepath)\n","\n","max_epochs = len(train_losses)\n","val_interval = 2  # Update this if your validation interval is different\n","\n","# Plotting\n","plt.figure(figsize=(14, 6))\n","plt.plot(range(1, max_epochs + 1), train_losses, label='Training Loss', color='blue', alpha=0.9)\n","plt.plot(range(2, max_epochs + 1, val_interval), val_losses, label='Validation Loss', color='orange', alpha=0.8)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Losses')\n","plt.legend()\n","plt.xticks(np.arange(1, max_epochs + 1, 10))  # Adjust the x-axis ticks if needed\n","plt.show()\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DyUnet is set:\n","Kernel size:  [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n","Strides:  [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 1]]\n"]}],"source":["import os\n","import torch\n","from model_maker import get_network\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = get_network(patch_size = [168, 168, 16], spacing = [4.07, 4.07, 3.00])\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from monai.networks.nets import DynUNet\n","\n","\n","# def get_kernels_strides(patch_size, spacing):\n","#     \"\"\"\n","#     Adjusted function to use the correct variable names.\n","#     \"\"\"\n","#     sizes = patch_size  \n","#     spacings = spacing  \n","#     strides, kernels = [], []\n","#     while True:\n","#         spacing_ratio = [sp / min(spacings) for sp in spacings]\n","#         stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n","#         kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n","#         if all(s == 1 for s in stride):\n","#             break\n","#         for idx, (i, j) in enumerate(zip(sizes, stride)):\n","#             if i % j != 0:\n","#                 raise ValueError(\n","#                     f\"Patch size is not supported, please try to modify the size {patch_size[idx]} in the spatial dimension {idx}.\"\n","#                 )\n","#         sizes = [i / j for i, j in zip(sizes, stride)]\n","#         spacings = [i * j for i, j in zip(spacings, stride)]\n","#         kernels.append(kernel)\n","#         strides.append(stride)\n","\n","#     strides.insert(0, len(spacings) * [1])\n","#     kernels.append(len(spacings) * [3])\n","#     return kernels, strides\n","\n","# class CustomDynUNet(DynUNet):\n","#     def __init__(self, *args, **kwargs):\n","#         super().__init__(*args, **kwargs)\n","#         # Assuming that the final layer is named 'output_block' and is a single convolutional layer\n","#         # You could potentially add a ReLU layer right after it if it's not already included\n","#         self.final_relu = torch.nn.ReLU()\n","\n","#     def forward(self, x):\n","#         x = super().forward(x)\n","#         # Apply ReLU to the output\n","#         x = self.final_relu(x)\n","#         return x\n","\n","# # Example of initializing your custom model, assuming you have the parameters `kernels`, `strides`, etc.\n","# # You should replace these with the actual values or methods you use to get them.\n","# kernels, strides = get_kernels_strides(patch_size, spacing)\n","\n","# model = CustomDynUNet(\n","#     spatial_dims=3,\n","#     in_channels=1,\n","#     out_channels=1,\n","#     kernel_size=kernels,\n","#     strides=strides,\n","#     upsample_kernel_size=strides[1:],\n","#     norm_name=\"INSTANCE\",\n","#     # The activation is not set here since we're adding it manually in the forward method\n","#     deep_supervision=True,\n","#     deep_supr_num=2,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn\n","\n","\n","# # Iteratively inspect the model\n","# for name, module in model.named_modules():\n","#     print(name, \"=>\", module)\n","\n","# To specifically check for an activation function at the last layer, you might need to know the structure.\n","# Assuming 'net' is your model:\n","last_layer = list(model.children())[-1]\n","print(last_layer)\n","\n","# # If the last layer is a Sequential block or similar, you might need to go one level deeper:\n","# if isinstance(last_layer, nn.Sequential):\n","#     last_sublayer = list(last_layer.children())[-1]\n","#     print(\"Last sub-layer:\", last_sublayer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","# Assuming root_dir is the directory where your model files are stored\n","model_path = os.path.join(log_dir, bestmodel_filename)\n","if os.path.exists(model_path):\n","    print(f\"Model file {bestmodel_filename} is loading.\")\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","else:\n","    print(f\"Model file {bestmodel_filename} not found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract file names\n","test_name = [(os.path.splitext(os.path.basename(file_info['image']))[0], os.path.splitext(os.path.basename(file_info['target']))[0]) for file_info in test_files]\n","test_name\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from data_preparation import visualize_coronal_slice\n","\n","roi_size = (160, 160, 32)\n","sw_batch_size = 64\n","slice_number = 95\n","\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader):\n","\n","        predict = sliding_window_inference(data[\"image\"].to(device), roi_size,\n","                          sw_batch_size, model, progress=True, overlap=0.70)\n","        \n","        visualize_coronal_slice(data, predict, slice_number, \n","                                f\"{bestmodel_filename}\\nepoch: {best_epoch}, best_metric: {best_metric}\", \n","                                \"jet\", Norm=False)\n","        if i == 2:\n","            break\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [160, 160, 32] and output size of torch.Size([1, 160, 160, 32]). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     28\u001b[0m     test_inputs \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m     test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msw_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.70\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     post_processed \u001b[38;5;241m=\u001b[39m [post_transforms(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(test_data)]\n","File \u001b[0;32m/students/2023-2024/master/Shahpouri/.venv/lib/python3.11/site-packages/monai/inferers/utils.py:264\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, progress, roi_weight_map, process_fn, buffer_steps, buffer_dim, with_coord, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buffered \u001b[38;5;129;01mand\u001b[39;00m seg_shape \u001b[38;5;241m!=\u001b[39m roi_size:\n\u001b[1;32m    263\u001b[0m     z_scale \u001b[38;5;241m=\u001b[39m [out_w_i \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(in_w_i) \u001b[38;5;28;01mfor\u001b[39;00m out_w_i, in_w_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(seg_shape, roi_size)]\n\u001b[0;32m--> 264\u001b[0m     w_t \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_nearest_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_image_list) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m ss:\n\u001b[1;32m    266\u001b[0m     output_shape \u001b[38;5;241m=\u001b[39m [batch_size, seg_chns]\n","File \u001b[0;32m/students/2023-2024/master/Shahpouri/.venv/lib/python3.11/site-packages/torch/nn/functional.py:3934\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   3933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m-> 3934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput and output must have the same number of spatial dimensions, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3936\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput with spatial dimensions of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and output size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3937\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide input tensor in (N, C, d1, d2, ...,dK) format and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3938\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput size in (o1, o2, ...,oK) format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3939\u001b[0m         )\n\u001b[1;32m   3940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m   3941\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_integer(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m size):\n","\u001b[0;31mValueError\u001b[0m: Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [160, 160, 32] and output size of torch.Size([1, 160, 160, 32]). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format."]}],"source":["\n","from monai.transforms import Compose\n","from data_preparation import ClampNegative\n","\n","\n","roi_size = (160, 160, 32)\n","sw_batch_size = 64\n","\n","\n","post_transforms = Compose(\n","    [\n","        Invertd(\n","            keys=\"pred\",\n","            transform=loader_factory.get_test_transforms(),\n","            orig_keys=\"image\",\n","            meta_keys=\"pred_meta_dict\",\n","            orig_meta_keys=\"image_meta_dict\",\n","            meta_key_postfix=\"meta_dict\",\n","            nearest_interp=False,\n","            to_tensor=True,\n","        ),\n","        ClampNegative(keys=[\"pred\"]),\n","        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=output_dir, output_postfix=\"dl3_18\", resample=False), \n","    ]\n",")\n","\n","with torch.no_grad():\n","    for test_data in test_loader:\n","        test_inputs = test_data[\"image\"].to(device)\n","        test_data[\"pred\"] = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model, overlap=0.70)\n","        post_processed = [post_transforms(i) for i in decollate_batch(test_data)]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import os\n","# import glob\n","# from utils import PairFinder\n","# hint = 'dl_dyn2'\n","# hint = 'gamodel_3_18_onfdg'\n","# hint = 'Areset_test'\n","\n","# pair_finder = PairFinder(f'{fdg_data_dir}/MAC', output_dir, hint)\n","# test_dict_list = pair_finder.find_file_pairs()\n","# test_dict_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import nibabel as nib\n","# import os\n","\n","# for item in test_dict_list:\n","#     predicted_image_path = item['predicted']\n","#     reference_image_path = item['reference']\n","    \n","#     # Handle the '.nii.gz' extension properly\n","#     if predicted_image_path.endswith('.nii.gz'):\n","#         base_path = predicted_image_path[:-7]  # Remove '.nii.gz' from the end\n","#         corrected_dl_image_path = f\"{base_path}_corr.nii.gz\"\n","#     else:\n","#         # For other extensions, split and append '_corrected' before the extension\n","#         base_path, ext = os.path.splitext(predicted_image_path)\n","#         corrected_dl_image_path = f\"{base_path}_corr{ext}\"\n","    \n","#     # Load the reference (original) image to get its affine and header\n","#     orig = nib.load(reference_image_path)\n","    \n","#     # Load the DL predicted image\n","#     dl = nib.load(predicted_image_path)\n","#     dl_data = dl.get_fdata()\n","    \n","#     # Create a new NIfTI image using the DL data but with the original affine and header\n","#     corrected_dl_img = nib.Nifti1Image(dl_data, orig.affine, header=orig.header.copy())\n","    \n","#     # Save the corrected DL image\n","#     nib.save(corrected_dl_img, corrected_dl_image_path)\n"," \n","#     print(f\"Corrected image saved to: {corrected_dl_image_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Second method:\n","# import numpy as np\n","# import nibabel as nib\n","# import os\n","\n","# def write_nifti(data, file_name, affine, output_dtype=np.float32):\n","#     \"\"\"\n","#     Writes the given NIfTI data to a file.\n","\n","#     Parameters:\n","#     - data: The image data to write.\n","#     - file_name: The path to the file where the data should be saved.\n","#     - affine: The affine matrix for the NIfTI image.\n","#     - output_dtype: The desired data type for the saved image.\n","#     \"\"\"\n","#     img = nib.Nifti1Image(data.astype(output_dtype), affine)\n","#     img.to_filename(file_name)\n","\n","# # Assuming test_dict_list is defined as shown in your example\n","# for item in test_dict_list:\n","#     predicted_image_path = item['predicted']\n","#     reference_image_path = item['reference']\n","    \n","#     if predicted_image_path.endswith('.nii.gz'):\n","#         base_path = predicted_image_path[:-7]  # Correctly handles '.nii.gz' extension\n","#         corrected_dl_image_path = f\"{base_path}_corr2.nii.gz\"\n","#     else:\n","#         base_path, ext = os.path.splitext(predicted_image_path)\n","#         corrected_dl_image_path = f\"{base_path}_corr2{ext}\"\n","    \n","#     orig = nib.load(reference_image_path)\n","#     dl = nib.load(predicted_image_path)\n","#     dl_data = np.asanyarray(dl.dataobj)  # Directly accessing data\n","    \n","#     # Using write_nifti to save the corrected DL image\n","#     write_nifti(dl_data, corrected_dl_image_path, orig.affine, np.float32)\n","    \n","#     print(f\"Corrected image saved to: {corrected_dl_image_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import nibabel as nib\n","# import numpy as np\n","\n","# original_image_path = '/students/2023-2024/master/Shahpouri/DATA/FDG_TEST/MAC/006051_dataset_07_A.nii.gz'\n","# dl_image_path = '/students/2023-2024/master/Shahpouri/OUTPUT/006051_dataset_07_A/006051_dataset_07_A_test.nii.gz'\n","# corrected_dl_image_path = '/students/2023-2024/master/Shahpouri/OUTPUT/006051_dataset_07_A/006051_dataset_07_A_corrected.nii.gz'\n","\n","# # Load the original image to get its affine and header\n","# orig = nib.load(original_image_path)\n","\n","# # Load the DL predicted image\n","# dl = nib.load(dl_image_path)\n","# # Extract the data from the DL predicted image\n","# dl_data = dl.get_fdata()\n","\n","# # Create a new NIfTI image using the DL data but with the original affine and header\n","# corrected_dl_img = nib.Nifti1Image(dl_data, orig.affine, header=orig.header.copy())\n","\n","# # Save the DL image with the updated header to the corrected path\n","# nib.save(corrected_dl_img, corrected_dl_image_path)\n","\n","# # Load the newly saved corrected DL image\n","# dl_new = nib.load(corrected_dl_image_path)\n","\n","# # Print the affine matrix for verification\n","# print(\"Affine matrix for original image:\", orig.affine)\n","# print(\"Affine matrix for dl image:\", dl.affine)\n","# print(\"Affine matrix for corrected dl image:\", dl_new.affine)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1JG1lbZwQZ1TZS1EVyy_8ALByR6PaA5EJ","timestamp":1705418268395},{"file_id":"1E8ibC7ZVGwMZwubrqCgHcjS0GUHMG8-T","timestamp":1705308567486}]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
