{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.transforms import Compose, Invertd, SaveImaged\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "import torch\n",
    "import json\n",
    "from utils import PairFinder\n",
    "from quant import masked_SUV_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/students/2023-2024/master/Shahpouri/DL_PET/config.json'\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "ga_data_dir = config[\"ga_data_dir\"]\n",
    "fdg_data_dir = config[\"fdg_data_dir\"]\n",
    "log_dir = config[\"log_dir\"]\n",
    "ga_output_dir = config[\"ga_output_dir\"]\n",
    "artifact_dir = config[\"artifacts\"]\n",
    "artifact_output = config [\"artifact_output\"]\n",
    "fdg_output_dir = config['fdg_output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data length: 98\n",
      "Validation data length: 0\n",
      "Train data length: 0\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import ExternalRadioSetHandling\n",
    "from data_preparation import LoaderFactory\n",
    "\n",
    "data_handler = ExternalRadioSetHandling(data_dir=fdg_data_dir, test_ratio=1)\n",
    "train_files, val_files, test_files = data_handler.get_split_data()\n",
    "\n",
    "print(f\"Test data length: {len(test_files)}\")\n",
    "print(f\"Validation data length: {len(val_files)}\")\n",
    "print(f\"Train data length: {len(train_files)}\")\n",
    "\n",
    "\n",
    "loader_factory = LoaderFactory(\n",
    "    train_files=None,\n",
    "    val_files=None,\n",
    "    test_files=test_files,\n",
    "    patch_size = [168, 168, 16],\n",
    "    spacing = [4.07, 4.07, 3.00],\n",
    "    # spacing = [1.92, 1.92, 3.27], # For fdg data\n",
    "    spatial_size = (168, 168, 400)\n",
    "    # spatial_size = (336, 336, 640) # for Fdg data\n",
    "    # spatial_size = (168, 168, 600) # for Fdg data\n",
    "    )\n",
    "\n",
    "# train_loader = loader_factory.get_loader('train', batch_size=4, num_workers=2, shuffle=True)\n",
    "# val_loader = loader_factory.get_loader('val', batch_size=1, num_workers=2, shuffle=False)\n",
    "test_loader = loader_factory.get_loader('test', batch_size=1, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint1 = 'dl3_18'\n",
    "hint1 = 'dl4_23'\n",
    "pair_finder_dl3_18 = PairFinder(f'{ga_data_dir}/NAC', f'{ga_data_dir}/MAC', ga_output_dir, hint1)\n",
    "_, center_pairs_dyn  = pair_finder_dl3_18.find_file_triples()\n",
    "\n",
    "\n",
    "hint2 = 'dl_final'\n",
    "hint2 = 'final_4_26'\n",
    "pair_finder_adcm = PairFinder(f'{ga_data_dir}/NAC',f'{ga_data_dir}/MAC', ga_output_dir, hint2)\n",
    "_, center_pairs_adcm  = pair_finder_adcm.find_file_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(pairs):\n",
    "    concatenated_pred = []\n",
    "    concatenated_ref = []\n",
    "    for pair in pairs:\n",
    "        # Apply the mask and get the predicted image data\n",
    "        _, masked_predicted_img, masked_reference_img = masked_SUV_img(\n",
    "            pair['nac'], pair['predicted'], pair['reference'], nac_factor=2, mac_factor=5, mask_val=0.3)\n",
    "        concatenated_pred.extend(masked_predicted_img.ravel())  # Flatten and collect data\n",
    "        concatenated_ref.extend(masked_reference_img.ravel())\n",
    "    return concatenated_pred, concatenated_ref\n",
    "\n",
    "# Obtain paths from the dictionaries for each center\n",
    "center = 'C1'\n",
    "adcm_paths = center_pairs_adcm[center]\n",
    "imcm_paths = center_pairs_dyn[center]\n",
    "\n",
    "# Load and prepare the data for statistical testing\n",
    "imcm_data, mac_data = load_and_prepare_data(imcm_paths)\n",
    "adcm_data, _ = load_and_prepare_data(adcm_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-statistic: 187094849484524.5\n",
      "P-value: 7.686508384218115e-23\n",
      "Reject the null hypothesis - suggest the distribution of the two samples are significantly different.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from quant import load_nifti_image\n",
    "\n",
    "# Perform the Mann-Whitney U Test\n",
    "stat, p_value = mannwhitneyu(adcm_data, imcm_data, alternative='two-sided')\n",
    "\n",
    "print(\"U-statistic:\", stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpretation of the result\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis - suggest the distribution of the two samples are significantly different.\")\n",
    "else:\n",
    "    print(\"Do not reject the null hypothesis - suggest the distribution of the two samples are not significantly different.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-statistic: 187998483815357.5\n",
      "P-value: 1.2603516982102084e-58\n",
      "Reject the null hypothesis - suggest the distribution of the two samples are significantly different.\n"
     ]
    }
   ],
   "source": [
    "stat, p_value = mannwhitneyu(mac_data, imcm_data, alternative='two-sided')\n",
    "\n",
    "print(\"U-statistic:\", stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "alpha = 0.02  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis - suggest the distribution of the two samples are significantly different.\")\n",
    "else:\n",
    "    print(\"Do not reject the null hypothesis - suggest the distribution of the two samples are not significantly different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = mannwhitneyu(mac_data, adcm_data, alternative='two-sided')\n",
    "\n",
    "print(\"U-statistic:\", stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis - suggest the distribution of the two samples are significantly different.\")\n",
    "else:\n",
    "    print(\"Do not reject the null hypothesis - suggest the distribution of the two samples are not significantly different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# Step1: Mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Error (SUV)</th>\n",
       "      <th>Mean Absolure Error (SUV)</th>\n",
       "      <th>Relative Error (SUV%)</th>\n",
       "      <th>Absolure Relative Error (SUV%)</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Peak Signal-to-Noise Ratio</th>\n",
       "      <th>Structual Similarity Index</th>\n",
       "      <th>Center</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.391218</td>\n",
       "      <td>1.948693</td>\n",
       "      <td>-3.455760</td>\n",
       "      <td>47.764912</td>\n",
       "      <td>7.159046</td>\n",
       "      <td>47.464313</td>\n",
       "      <td>0.857655</td>\n",
       "      <td>C1</td>\n",
       "      <td>ADCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121809</td>\n",
       "      <td>1.248694</td>\n",
       "      <td>19.078541</td>\n",
       "      <td>48.547640</td>\n",
       "      <td>3.226209</td>\n",
       "      <td>39.599713</td>\n",
       "      <td>0.911650</td>\n",
       "      <td>C1</td>\n",
       "      <td>ADCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593124</td>\n",
       "      <td>2.198104</td>\n",
       "      <td>17.919191</td>\n",
       "      <td>63.563060</td>\n",
       "      <td>6.744680</td>\n",
       "      <td>37.347102</td>\n",
       "      <td>0.837137</td>\n",
       "      <td>C2</td>\n",
       "      <td>ADCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.273347</td>\n",
       "      <td>2.408490</td>\n",
       "      <td>26.668924</td>\n",
       "      <td>63.049635</td>\n",
       "      <td>8.056123</td>\n",
       "      <td>35.262026</td>\n",
       "      <td>0.813911</td>\n",
       "      <td>C2</td>\n",
       "      <td>ADCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.883905</td>\n",
       "      <td>3.928055</td>\n",
       "      <td>37.376147</td>\n",
       "      <td>64.617671</td>\n",
       "      <td>20.673146</td>\n",
       "      <td>36.070237</td>\n",
       "      <td>0.899456</td>\n",
       "      <td>C3</td>\n",
       "      <td>ADCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Error (SUV)  Mean Absolure Error (SUV)  Relative Error (SUV%)  \\\n",
       "0         -0.391218                   1.948693              -3.455760   \n",
       "1          0.121809                   1.248694              19.078541   \n",
       "2          0.593124                   2.198104              17.919191   \n",
       "3          1.273347                   2.408490              26.668924   \n",
       "4          2.883905                   3.928055              37.376147   \n",
       "\n",
       "   Absolure Relative Error (SUV%)  Root Mean Squared Error  \\\n",
       "0                       47.764912                 7.159046   \n",
       "1                       48.547640                 3.226209   \n",
       "2                       63.563060                 6.744680   \n",
       "3                       63.049635                 8.056123   \n",
       "4                       64.617671                20.673146   \n",
       "\n",
       "   Peak Signal-to-Noise Ratio  Structual Similarity Index Center Dataset  \n",
       "0                   47.464313                    0.857655     C1    ADCM  \n",
       "1                   39.599713                    0.911650     C1    ADCM  \n",
       "2                   37.347102                    0.837137     C2    ADCM  \n",
       "3                   35.262026                    0.813911     C2    ADCM  \n",
       "4                   36.070237                    0.899456     C3    ADCM  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'Results/combined_data.csv'\n",
    "combined_data = pd.read_csv(file_path)\n",
    "\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMCM vs MAC - U-statistic: 186875549033538.5 P-value: 1.2603516982102084e-58\n",
      "ADCM vs MAC - U-statistic: 186529828166413.5 P-value: 5.639571034021006e-150\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Compare IMCM and MAC\n",
    "stat_imcm, p_value_imcm = mannwhitneyu(imcm_data, mac_data, alternative='two-sided')\n",
    "\n",
    "# Compare ADCM and MAC\n",
    "stat_adcm, p_value_adcm = mannwhitneyu(adcm_data, mac_data, alternative='two-sided')\n",
    "\n",
    "print(\"IMCM vs MAC - U-statistic:\", stat_imcm, \"P-value:\", p_value_imcm)\n",
    "print(\"ADCM vs MAC - U-statistic:\", stat_adcm, \"P-value:\", p_value_adcm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# Step 2: False Discovery Rate (FDR) Correction\n",
    "We'll apply the Benjamini-Hochberg procedure to correct the p-values obtained from multiple comparisons to control the false discovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Combine p-values from both tests\n",
    "p_values = [p_value_imcm, p_value_adcm]\n",
    "\n",
    "# Apply Benjamini-Hochberg correction\n",
    "_, p_adjusted, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"Adjusted P-values:\", p_adjusted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# Step 3: Intraclass Correlation Coefficient (ICC)\n",
    "To assess consistency, specifically the reproducibility between IMCM, ADCM, and MAC, we use ICC. Python's pingouin library provides a convenient function to compute ICC from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare a DataFrame for ICC calculation\n",
    "df = pd.DataFrame({\n",
    "    'MAC': mac_data,\n",
    "    'IMCM': imcm_data,\n",
    "    'ADCM': adcm_data\n",
    "})\n",
    "\n",
    "# Calculate ICC\n",
    "icc_results = pg.intraclass_corr(data=df, targets='MAC', raters=['IMCM', 'ADCM'], ratings='folded', model='twoway', type=1)\n",
    "icc_value = icc_results.set_index('Type').at['ICC1', 'ICC']\n",
    "\n",
    "print(\"ICC value:\", icc_value)\n",
    "print(icc_results[['ICC', 'CI95%']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Step 4: Classify Reproducibility Based on ICC\n",
    "Based on the ICC value, classify the reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_icc(icc_val):\n",
    "    if icc_val < 0.40:\n",
    "        return 'Poor reproducibility'\n",
    "    elif 0.40 <= icc_val < 0.59:\n",
    "        return 'Fair reproducibility'\n",
    "    elif 0.60 <= icc_val < 0.74:\n",
    "        return 'Good reproducibility'\n",
    "    else:\n",
    "        return 'Excellent reproducibility'\n",
    "\n",
    "reproducibility = classify_icc(icc_value)\n",
    "print(\"Reproducibility:\", reproducibility)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
